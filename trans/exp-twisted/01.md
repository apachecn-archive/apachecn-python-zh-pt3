# 一、Twisted 事件驱动编程简介

Twisted 是一个强大的、经过充分测试的、成熟的并发网络库和框架。正如我们将在本书中看到的，十多年来，许多项目和个人都使用了它，并取得了巨大的成效。

同时，Twisted 是大型的、复杂的、古老的。它的词典里充斥着奇怪的名字，比如“反应堆”、“协议”、“终点”和“延迟”。这些描述了一种哲学和架构，这种哲学和架构让具有多年 Python 经验的新手和老手都感到困惑。

两个基本的编程范例通知了 Twisted 的 API 万神殿:*事件驱动编程*和*异步编程*。JavaScript 的兴起和`asyncio`在 Python 标准库中的引入使这两者进一步成为主流，但是这两种范式都没有完全主导 Python 编程，以至于仅仅了解这种语言就使它们变得熟悉。它们仍然是为中级或高级程序员保留的专门主题。

本章和下一章将介绍事件驱动和异步编程背后的动机，然后展示 Twisted 如何使用这些范例。它们为后面探索真实世界 Twisted 程序的章节奠定了基础。

我们将从探索 Twisted 环境之外的事件驱动编程的本质开始。一旦我们了解了事件驱动编程的定义，我们将会看到 Twisted 如何提供软件抽象来帮助开发人员编写清晰有效的事件驱动程序。我们还将沿途停下来了解这些抽象的一些独特部分，如*接口*，并探索它们是如何在 Twisted 的网站上记录的。

在这一章结束时，你将知道 Twisted 的术语:协议、传输、反应器、消费者和生产者。这些概念构成了 Twisted 事件驱动编程方法的基础，了解这些概念对于用 Twisted 编写有用的软件是必不可少的。

## 关于 Python 版本的说明

Twisted 本身支持 Python 2 和 3，所以本章中的所有代码示例都可以在 Python 2 和 3 上运行。Python 3 是未来，但 Twisted 的部分优势在于其丰富的协议实现历史；出于这个原因，即使您从未编写过代码，也要熟悉在 Python 2 上运行的代码，这一点很重要。

## 什么是事件驱动编程？

一个*事件*是导致一个事件驱动程序执行一个动作的东西。这个宽泛的定义允许许多程序被理解为事件驱动的；例如，考虑一个根据用户输入打印`Hello`或`World!`的简单程序:

```py
import sys
line = sys.stdin.readline().strip()
if line == "h":
     print("Hello")
else:
     print("World")

```

超过标准输入的输入行的可用性是一个事件。我们的程序在`sys.stdin.readline()`暂停，它要求操作系统允许用户输入一个完整的行。直到收到一个，我们的计划才能取得进展。当操作系统接收到输入，Python 的内部机制确定它是一行时，`sys.stdin.readline()`通过将数据返回给它来恢复我们的程序。这次恢复是推动我们计划向前发展的事件。那么，即使这个简单的程序也可以理解为一个*事件驱动的*程序。

## 多个事件

接收单个事件然后退出的程序不会从事件驱动的方法中受益。然而，一次可以发生多件事情的程序更自然地围绕事件来组织。图形用户界面就意味着这样一个程序:在任何时候，用户都可能点击一个按钮，从菜单中选择一个项目，滚动一个文本小部件，等等。

这是我们之前的程序的一个版本，带有 Tkinter GUI:

```py
from six.moves import tkinter
from six.moves.tkinter import scrolledtext

class Application(tkinter.Frame):
    def __init__ (self, root):
        super(Application,self). __init__ (root)
        self.pack()
        self.helloButton = tkinter.Button(self,
                                      text="Say Hello",
                                      command=self.sayHello)
        self.worldButton = tkinter.Button(self,
                                        text="Say World",
                                        command=self.sayWorld)
         self.output = scrolledtext.ScrolledText(master=self)
         self.helloButton.pack(side="top")
        self.worldButton.pack(side="top")
         self.output.pack(side="top")
    def outputLine(self, text):
        self.output.insert(tkinter.INSERT, text+ '\n')
    def sayHello(self):
        self.outputLine("Hello")
    def sayWorld(self):
        self.outputLine("World")

```

## 应用(tkinter。Tk())。主循环()

这个版本的程序为用户提供了两个按钮，每个按钮都可以生成一个独立的点击事件。这与我们之前的程序不同，在我们之前的程序中，只有`sys.stdin.readline`可以生成单个“生产线就绪”事件。

我们通过将*事件处理程序*与每一个相关联来处理每个按钮事件可能发生的情况。Tkinter 按钮接受一个可调用的`command`以在被点击时调用。当标有“Say Hello”的按钮生成一个点击事件时，该事件驱动我们的程序调用`Application.sayHello`，如图 [1-1](#Fig1) 所示。这反过来将由`Hello`组成的一行输出到一个可滚动的文本小部件。同样的过程也适用于标有“Say Hello”和`Application.sayWorld`的按钮。

![img/455189_1_En_1_Fig1_HTML.jpg](img/455189_1_En_1_Fig1_HTML.jpg)

图 1-1

我们的 Tkinter GUI 应用在一系列点击“说你好”和“说世界”之后

我们的`Application`类继承的`tkinter.Frame`的`mainloop`方法，等待绑定到它的按钮生成一个事件，然后运行相关的事件处理程序。在每个事件处理程序运行之后，`tkinter.Frame.mainloop`再次开始等待新的事件。一个监视事件源并分派其相关处理程序的循环是典型的事件驱动程序，被称为*事件循环*。

这些概念是事件驱动编程的核心:

1.  *事件*表示某件事情已经发生，程序应该对此做出反应。在我们的两个例子中，事件自然地对应于程序输入，但是正如我们将看到的，它们可以表示导致我们的程序执行一些动作的任何东西。

2.  *事件处理程序*构成了程序对事件的反应。有时一个事件的处理程序仅仅由一系列代码组成，就像我们的`sys.stdin.readline`例子一样，但是更多的时候它被一个函数或方法封装，就像我们的`tkinter`例子一样。

3.  一个*事件循环*等待事件并调用与每个事件相关的事件处理程序。不是所有的事件驱动程序都有事件循环；我们的例子没有，因为它只响应单个事件。然而，大多数类似于我们的`tkinter`例子，它们在最终退出之前处理许多事件。这类程序使用事件循环。

## 多路复用和解复用

事件循环等待事件的方式影响了我们编写事件驱动程序的方式，所以我们必须仔细研究一下。考虑我们的`tkinter`例子及其两个按钮；`mainloop`中的事件循环必须等到用户至少点击了一个按钮。一个简单的实现可能如下所示:

```py
def mainloop(self):
    while self.running:
         ready = [button for button in self.buttons if button.hasEvent()]
         if ready:
            self.dispatchButtonEventHandlers(ready)

```

`mainloop`不断地*为新事件轮询*每个按钮，只为那些准备好事件的按钮分派事件处理程序。当没有事件准备好时，程序没有进展，因为没有采取需要响应的动作。事件驱动程序必须在这些不活动期间暂停执行。

在我们的`mainloop`例子中，while 循环暂停它的程序，直到其中一个按钮被点击，并且`sayHello`或`sayWorld`应该运行。除非用户使用鼠标的速度超乎寻常的快，否则这个循环大部分时间都花在检查没有被点击的按钮上。这被称为*忙等待*，因为程序正在积极地忙等待。

像这样的繁忙等待会暂停程序的整体执行，直到它的一个事件源报告一个事件，因此它足以作为一种暂停事件循环的机制。

驱动我们的实现忙碌等待的内部列表理解提出了一个关键问题:发生了什么事情吗？答案来自于`ready`变量，这个变量包含了在一个地方被点击过的所有按钮。`ready`的真决定了事件循环问题的答案:当`ready`为空因而为假时，没有按钮被点击，所以什么也没发生。然而，当它是真的时，至少有一个被点击了，所以一些事情*已经*发生了。

构建`ready`的列表理解将许多独立的输入合并成一个。这被称为*多路复用*，而从单个合并的输入中分离出不同输入的逆过程被称为*解复用*。列表理解将我们的按钮复用到`ready`中，而`dispatchButtonEventHandlers`方法通过调用每个事件的处理程序将它们解复用出来。

现在，我们可以通过精确描述事件循环等待事件的方式来完善我们对事件循环的理解:

*   一个*事件循环*通过*将事件源*复用到一个输入中来等待事件。当该输入指示事件已经发生时，事件循环将其解复用为组成输入，并调用与每个输入相关联的事件处理程序。

我们的`mainloop`复用器浪费了大部分时间来轮询没有被点击的按钮。并非所有多路复用器都如此低效。`tkinter.Frame.mainloop`的实际实现使用了一个类似的多路复用器来轮询所有的小部件，除非操作系统提供了更有效的原语。为了提高效率，`mainloop`的多路复用器利用了计算机检查 GUI 部件的速度比人与它们互动的速度更快的洞察力，并插入了一个`sleep`调用，使整个程序暂停几毫秒。这允许程序被动地花费部分忙等待循环，而不是主动地什么都不做，以可忽略的延迟为代价节省 CPU 时间和能量。

虽然 Twisted 可以与图形用户界面集成，并且事实上对`tkinter`有特殊的支持，但它本质上是一个网络引擎。*套接字*，而不是按钮，是网络中的基本对象，操作系统公开了用于复用套接字事件的有效原语。Twisted 的事件循环使用这些原语来等待事件。要理解 Twisted 的事件驱动编程方法，我们必须理解这些套接字和这些多路复用网络原语之间的交互。

## `select`复用器

### 它的历史，它的兄弟姐妹，和它的目的

几乎所有现代操作系统都支持`select`多路复用器。`select`之所以得名，是因为它能够获取一个套接字列表，并且只“选择”那些具有准备好处理的事件的套接字。

诞生于 1983 年，那时计算机的能力远不及现在。因此，它的接口使它无法以最高效率运行，尤其是在复用大量套接字时。每个操作系统家族都提供了自己的、更高效的多路复用器，比如 BSD 的`kqueue`和 Linux 的`epoll`，但是没有两个能够互操作。幸运的是，它们的原理与`select`非常相似，我们可以从`select`的原理中归纳出它们的行为。我们将使用`select`来探究这些插座多路复用器的行为。

### `select`和插座

下面的代码省略了错误处理，并将在实践中出现的许多边缘情况下中断。它只是作为一种教学工具。不要在实际应用中使用它。用 Twisted 代替。 Twisted 力求正确处理错误和边缘情况；这也是它的实现如此复杂的部分原因。

排除了免责声明，让我们开始一个交互式 Python 会话，并为`select`创建套接字以进行多路传输:

```py
>>> import socket
>>> listener = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
>>> listener.bind(('127.0.0.1', 0))
>>> listener.listen(1)
>>> client = socket.create_connection(listener.getsockname())
>>> server, _ = listener.accept()

```

对套接字 API 的完整解释超出了本书的范围。事实上，我们期望我们讨论的部分将引导您选择 Twisted！然而，前面的代码包含了比无关细节更基本的概念:

1.  `listener` -该插座可以*接受*输入连接。它是一个互联网(`socket.AF_INET`)和 TCP ( `socket.SOCK_STREAM`)套接字，客户端可以通过内部的、仅限本地的网络接口(通常有一个`127.0.0.1`地址)和操作系统(`0`)随机分配的端口进行访问。这个监听器可以为一个传入的连接执行必要的设置，并对其进行排队，直到我们读取它为止(`listen(1)`)。

2.  这个插座是一个输出连接。Python 的`socket.create_connection`函数接受一个代表要连接的监听套接字的`(host, port)`元组，并返回一个与之连接的套接字。因为我们的监听套接字在同一个进程中，并被命名为`listener`，所以我们可以用`listener.getsockname()`检索它的主机和端口。

3.  `server` -服务器的传入连接。一旦`client`连接到我们的主机和端口，我们必须接受来自`listener`的长度为 1 的队列的连接。`listener.accept`返回一个`(socket, address)`元组；我们只需要套接字，所以我们丢弃了地址。一个真正的程序可能会记录地址或使用它来跟踪连接度量。我们通过套接字的`listen`方法将监听队列设置为 1，在我们调用`accept`并允许`create_connection`返回之前，监听队列为我们保存这个套接字。

`client`和`server`是同一个 TCP 连接的两端。已建立的 TCP 连接没有“客户端”和“服务器”的概念；我们的`client`套接字与我们的`server`套接字具有相同的读、写或关闭连接的特权:

```py
>>> data = b"xyz"
>>> client.sendall(data)
>>> server.recv(1024) == data
True
>>> server.sendall(data)
>>> client.recv(1024) == data

True

```

### 套接字事件的方式和原因

在幕后，操作系统为每个 TCP 套接字维护读写缓冲区，以考虑网络的不可靠性以及以不同速度读写的客户端和服务器。如果`server`暂时无法接收数据，我们通过的`b"xyz"``client.sendall`将保留在其写缓冲区中，直到`server`再次变为活动状态。类似地，如果我们太忙而没有时间调用`client.recv`来接收发送的`b"xyz" server.sendall`，那么`client'`的读缓冲区会一直保存它，直到我们有时间接收它。我们传递的数字`recv`表示我们愿意从读缓冲区中移除的最大数据量。如果读缓冲区的数据小于最大值，如我们的例子所示，`recv`将从缓冲区中移除*所有的*数据并返回。

我们的套接字的双向性意味着两种可能的事件:

1.  一个*可读事件*，这意味着套接字有一些可用的东西。当数据到达套接字的接收缓冲区时，连接的服务器套接字会生成该事件，因此在可读事件后调用`recv`将立即返回该数据。断开由无数据的`recv`表示。按照惯例，当我们可以`accept`一个新的连接时，一个监听套接字会生成这个事件。

2.  一个*可写事件*，这意味着套接字的写缓冲区中有可用空间。这是一个微妙的问题:只要套接字从服务器接收到对数据的确认，它在网络上传输的速度比我们将数据添加到发送缓冲区的速度快，它就保持可写。

`select`的界面反映了这些可能的事件。它最多接受四个参数:

1.  监控*可读事件*的套接字序列；

2.  监控*可写事件*的套接字序列；

3.  监控“异常事件”的套接字序列在我们的例子中，不会发生异常事件，所以我们总是在这里传递一个空列表；

4.  一个可选的*超时*。这是`select`等待其中一个监视器套接字生成事件的秒数。省略这个参数将导致`select`永远等待。

我们可以询问`select`我们的套接字刚刚生成的事件:

```py
>>> import select
>>> maybeReadable = [listener, client, server]
>>> maybeWritable = [client, server]
>>> readable, writable, _ = select.select(maybeReadable, maybeWritable, [], 0)
>>> readable
[]
>>> writable == maybeWritable and writable == [client, server]
True

```

我们通过提供超时 0 来指示`select`不要等待任何新事件。如上所述，我们的`client`和`server`套接字可能是可读或可写的，而我们的`listener`只能接受传入的连接，只能是可读的。

如果我们忽略了超时，`select`会暂停我们的程序，直到它所监控的一个套接字变得可读或可写。这种执行的暂停类似于多路复用的 busy-wait，它在我们上面的天真的`mainloop`实现中轮询所有的按钮。

调用`select` *多路复用*套接字比繁忙等待更有效，因为操作系统只有在至少一个事件已经生成时才会恢复我们的程序；在内核内部，一个事件循环，与我们的`select`相似，等待来自网络硬件的事件，并将它们分派给我们的应用。

### 处理事件

`select`返回一个包含三个列表的元组，顺序与其参数相同。迭代每个返回的列表*解复用* `select`的返回值。我们的套接字都没有生成可读的事件，尽管我们已经将数据写入了`client`和`server`；我们之前对`recv`的调用清空了它们的读取缓冲区，自从我们接受`server`以来，没有新的连接到达`listener`。然而，`client`和`server`都生成了一个可写事件，因为它们的发送缓冲区中有可用空间。

从`client`向`server`发送数据导致`server`生成一个可读事件，因此`select`将其放入`readables`列表:

```py
>>> client.sendall(b'xyz')
>>> readable, writable, _ = select.select(maybeReadable, maybeWritable, [], 0)
>>> readable == [server]
True

```

有趣的是，`writable`列表再次包含了我们的`client`和`server`插座:

```py
>>> writable == maybeWritable and writable == [client, server]
True

```

如果我们再次调用`select`，我们的`server`插座将再次位于`readable`，我们的`client`和`server`插座将再次位于`writable`。原因很简单:只要数据保留在套接字的读缓冲区中，它就会连续生成一个可读事件，只要套接字的写缓冲区中还有空间，它就会生成一个可写事件。我们可以通过`recv`调用发送到`server`的数据`client`并再次调用`select`来确认新事件:

```py
>>> server.recv(1024) == b'xyz'
True
>>> readable, writable, _ = select.select(maybeReadable, maybeWritable, [], 0)
>>> readable
[]
>>> writable == maybeWritable and writable == [client, server]
True

```

清空`server`的读缓冲区导致它停止生成可读事件，而`client`和`server`继续生成可写事件，因为它们的写缓冲区还有空间。

### 带有`select`的事件循环

我们现在知道了`select`如何复用套接字:

1.  不同的套接字生成可读或可写的事件，以指示事件驱动的程序应该接受传入的数据或连接，或者写入传出的数据。

2.  `select`通过监视套接字的可读或可写事件来复用套接字，暂停程序，直到至少生成一个事件或可选的超时时间已过。

3.  套接字继续生成可读和可写事件，直到导致这些事件的环境发生变化:具有可读数据的套接字发出可读事件，直到其读缓冲区被清空；侦听套接字发出可读事件，直到所有传入连接都被接受；并且可写套接字发出可写事件，直到其写缓冲区被填满。

有了这些知识，我们可以围绕`select`勾画一个事件循环:

```py
import select

class Reactor(object):
    def __init__ (self):
        self._readers = {}
        self._writers = {}
    def addReader(self, readable, handler):
        self._readers[readable] = handler
    def addWriter(self, writable, handler):
        self._writers[writable] = handler
    def removeReader(self, readable):
        self._readers.pop(readable,None)
    def removeWriter(self, writable):
        self._writers.pop(writable,None)
    def run(self):
        while self._readers or self._writers:
            r, w, _ = select.select(list(self._readers), list(self._writers), [])
            for readable in r:
                self._readers[readable](self, readable)
            for writable in w:
                if writable in self._writers:
                   self._writers[writable](self, writable)

```

我们称我们的事件循环为*反应器*，因为它对套接字事件做出反应。我们可以请求我们的`Reactor`用`addReader`调用套接字上的可读事件处理程序，用`addWriter`调用可写事件处理程序。事件处理程序接受两个参数:反应器本身和生成事件的套接字。

`run`方法中的循环将我们的套接字与`select`进行多路复用，然后在产生读事件的套接字和产生写事件的套接字之间解复用结果。每个可读套接字的事件处理程序首先运行。然后，事件循环在运行其事件处理程序之前，检查每个可写套接字是否仍注册为编写器。这种检查是必要的，因为关闭的连接表示为读取事件，所以之前立即运行的读取处理程序可能会从读取器和写入器中移除关闭的套接字。当它的可写事件处理程序运行时，关闭的套接字将从`_writers`字典中移除。

### 事件驱动的客户端和服务器

这个简单的事件循环足以实现一个不断向服务器写入数据的客户端。我们将从事件处理程序开始:

```py
def accept(reactor, listener):
    server, _ = listener.accept()
    reactor.addReader(server, read)

def read(reactor, sock):
    data = sock.recv(1024)
    if data:
        print("Server received", len(data),"bytes.")
    else:
        sock.close()
        print("Server closed.")
        reactor.removeReader(sock)

DATA=[b"*",  b"*"]
def write(reactor, sock):
    sock.sendall(b"".join(DATA))
    print("Client wrote", len(DATA)," bytes.")
    DATA.extend(DATA)

```

`accept`函数通过接受传入连接并请求反应器监控可读事件来处理侦听套接字上的可读事件。这些由`read`函数处理。

`read`函数通过尝试从套接字的接收缓冲区接收固定数量的数据来处理套接字上的可读事件。任何接收到的数据的长度都会被打印出来——记住，传递给`recv`的数据量代表返回的字节数的*上限*。如果在已经生成可读事件的套接字上没有接收到数据，那么连接的另一端已经关闭了它的套接字，并且`read`函数通过关闭它的套接字端并将其从由反应器监视可读事件的套接字集中删除来做出响应。关闭套接字释放其操作系统资源，同时将其从反应器中移除确保了`select`多路复用器不会试图监控永远不会再次活动的套接字。

`write`函数将一系列星号`(*)`写入生成写事件的套接字。每次成功写入后，数据量都会翻倍。这模拟了真实网络应用的行为，这些应用不会始终如一地向一个连接写入相同数量的数据。考虑一个 web 浏览器:一些传出的请求包含用户键入的少量表单数据，而另一些请求将一个大文件上传到远程服务器。

注意，这些是模块级函数，而不是我们的`Reactor`类中的方法。相反，通过将它们注册为读取器或写入器，它们与反应器相关联，因为 TCP 套接字只是套接字的一种，我们必须处理它们的事件的方式不同于我们处理其他套接字事件的方式。然而，`select`的工作方式是一样的，不管它被赋予什么样的套接字，所以在它返回的套接字列表上运行事件处理程序的逻辑应该被`Reactor`类封装。稍后我们将会看到封装和它所隐含的接口对事件驱动程序有多重要。

我们现在可以建立一个`listener`和一个`client`，并允许事件循环驱动连接的接受和从`client`到服务器套接字的数据传输。

```py
import socket
listener = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
listener.bind(('127.0.0.1',0))
listener.listen(1)
client = socket.create_connection(listener.getsockname())

loop = Reactor()
loop.addWriter(client, write)
loop.addReader(listener, accept)
loop.run()

```

运行该程序会显示成功和失败:

```py
Client wrote 2 bytes.
Server received 2 bytes.
Client wrote 4 bytes.
Server received 4 bytes.
Client wrote 8 bytes.
Server received 8 bytes.
...
Client wrote 524288 bytes.
Server received 1024 bytes.
Client wrote 1048576 bytes.
Server received 1024 bytes.
^CTraceback (most recent call last):
  File "example.py", line 53, in <module>
    loop.run()
  File "example.py", line 25, in run
    writeHandler(self, writable)
  File "example.py", line 33, in write
    sock.sendall(b"".join(DATA))
KeyboardInterrupt

```

成功是显而易见的:数据从客户机套接字传递到服务器。这个行为遵循由`accept`、`read`和`write`事件处理程序设计的路径。正如所料，客户机首先向服务器发送两个字节的`b'*'`，服务器依次接收这两个字节。

客户机和服务器的同时性展示了事件驱动编程的威力。我们的 GUI 应用可以响应来自两个不同按钮的事件，而这个小型网络服务器现在可以响应来自客户端或服务器的事件，允许我们在一个进程中同时处理两者。`select`的多路复用能力在我们的程序事件循环中提供了一个单点，在这里它可以响应任何一个事件。

失败也是显而易见的:在一定次数的重复之后，我们的程序会冻结，直到它被键盘中断。这个失败的线索存在于我们程序的输出中；过了一会儿，客户机发送的数据量是服务器接收的数据量的许多倍，`KeyboardInterrupt`的回溯直接导致我们的`write`处理程序的`sock.sendall`调用。

我们的客户机使我们的服务器不堪重负，结果是客户机试图发送的大部分数据都留在它的套接字的发送缓冲区中。当在发送缓冲区中没有剩余空间的套接字上调用时，`sendall`的默认行为是暂停或*阻塞*程序。现在，如果`sendall`阻塞了*而*没有阻塞，并且我们的事件循环被允许运行，那么套接字就不会以可写的形式出现，阻塞的`sendall`调用也不会运行；然而，我们不能保证一个给定的发送调用会写足够的内容来填满一个套接字的发送缓冲区，这样`sendall`就不会阻塞，写处理程序会运行到完成，而`select`会阻止进一步的写操作，直到缓冲区耗尽。网络的本质是我们只有在这样的问题发生后才知道它。

到目前为止，我们报道的所有事件都促使我们的程序做一些事情。它们都不能促使它*停止*做某事。我们需要一种新的活动。

## 非阻塞输入输出

### 知道何时停止

默认情况下，套接字会阻止一个程序开始一项操作，直到远端执行某项操作，该操作才能完成。在这种情况下，我们可以通过请求操作系统使其*非阻塞*来使套接字发出一个事件。

让我们回到交互式 Python 会话，再次构建一个`client`和`server`套接字之间的连接。这一次，我们将使客户端成为非阻塞的，并尝试向其写入无限的数据流。

```py
>>> import socket
>>> listener = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
>>> listener.bind(( '127.0.0.1',0))
>>> listener.listen(1)
>>> client=socket.create_connection(listener.getsockname())
>>> server, _ = listener.accept()
>>> client.setblocking(False)
>>> while True: client.sendall(b"*"*1024)
...
Traceback (most recent call last):
  File"<stdin>", line1, in <module>
BlockingIOError: [Errno11] Resource temporarily unavailable

```

我们再次填充了`client`的发送缓冲区，但是`sendall`没有暂停进程，而是引发了一个异常。Python 2 和 3 中的异常类型有所不同；在这里，我们展示了 Python 3 的`BlockingIOError`，而在 Python 2 中，它将是更一般的`socket.error`。在 Python 的两个版本中，异常的`errno`属性将被设置为`errno.EAGAIN`:

```py
>>> import errno, socket
>>> try:
...    while True: client.sendall(b"*"*1024)
... except socket.error as e:
...    print(e.errno == errno.EAGAIN)
True

```

该异常表示操作系统生成的事件，指示我们应该*停止*写入。这几乎足以修复我们的客户端和服务器。

### 跟踪状态

然而，处理这个异常需要我们回答一个新问题:我们试图写入套接字发送缓冲区的数据有多少？不回答这个问题，我们就无法知道我们实际上发送了什么数据，也不知道我们无法用非阻塞套接字编写正确的程序。例如，网络浏览器必须跟踪它上传了多少文件，否则就有可能在传输过程中破坏文件内容。

在生成成为我们的异常的`EAGAIN`事件之前，`client.sendall`可以在它的写缓冲区中放置任意数量的字节。我们必须从套接字对象的`sendall`方法切换到`send`方法，该方法返回写入套接字发送缓冲区的数据量。我们可以用我们的`server`插座来证明这一点:

```py
>>> server.setblocking(False)
>>> try:
...    while True: print(server.send(b"*" * 1024))
... except socket.error as e:
...     print("Terminated with EAGAIN:", e.errno == errno.EAGAIN)
1024
1024
...
1024
952
Terminated with EAGAIN:True

```

我们将`server`标记为非阻塞，这样当它的发送缓冲区已满时，它会生成一个`EAGAIN`事件。然后`while`循环调用`server.send`。返回 1024 的调用已经将所有提供的字节写入套接字的发送缓冲区。最终套接字的写缓冲区被填满，一个代表`EAGAIN`事件的异常终止了循环。然而，循环终止前最后一次成功的`send`调用返回 952，这里 send 简单地丢弃了剩余的 72 个字节。这就是所谓的*短写*。阻塞套接字也会发生这种情况！因为当发送缓冲区中没有可用空间时它们会阻塞，而不是引发异常，`sendall`可以并且确实包含一个循环，该循环检查底层`send`调用的返回值并重新调用它，直到所有数据都被发送完。

在这种情况下，套接字的发送缓冲区不是 1024 的倍数，因此我们无法在到达`EAGAIN`之前将偶数个`send`调用的数据放入。然而，在现实世界中，套接字的发送缓冲区会根据网络中的条件改变大小，应用会通过连接发送不同数量的数据。使用非阻塞 I/O 的程序，比如我们假设的 web 浏览器，必须定期处理这样的短写。

我们可以使用`send`的返回值来确保我们将所有数据写入连接。我们维护自己的*缓冲区，其中包含我们想要写入的数据。每次`select`为该套接字发出一个可写事件时，我们试图`send`当前在缓冲区中的数据；如果`send`调用在没有引发`EAGAIN`的情况下完成，我们会记录返回的数量，并从我们的缓冲区的开头删除该数量的字节，因为`send`从它传递的字节序列的开头将数据写入发送缓冲区。另一方面，如果`send`引发了一个`EAGAIN`异常，表明发送缓冲区已满，无法接受更多数据，我们就让缓冲区保持原样。我们以这种方式进行，直到我们自己的缓冲区为空，此时我们知道所有的数据都已经放在了套接字的发送缓冲区中。之后，由操作系统将它发送到连接的接收端。*

我们现在可以通过将它的`write`函数分成一个初始化数据写入的函数和一个在`send`之上管理缓冲区的对象来修复我们简单的客户机-服务器示例:

```py
import errno
import socket

class BuffersWrites(object):
    def __init__ (self, dataToWrite, onCompletion):
        self._buffer = dataToWrite
        self._onCompletion = onCompletion
    def bufferingWrite(self, reactor, sock):
        if self._buffer:
            try:
                written = sock.send(self._buffer)
            except socket.error as e:
                if e.errno != errno.EAGAIN:
                    raise
                return
            else:
                print("Wrote", written,"bytes")
                self._buffer = self._buffer[written:]
        if not self._buffer:
                reactor.removeWriter(sock)
                self._onCompletion(reactor, sock)

DATA=[b"*", b"*"]
def write(reactor, sock):
    writer = BuffersWrites(b"".join(DATA), onCompletion=write)
    reactor.addWriter(sock, writer.bufferingWrite)
    print("Client buffering", len(DATA),"bytes to write.")
    DATA.extend(DATA)

```

`BuffersWrites`的初始化器的第一个参数是它将写入的字节，它将其用作缓冲区的初始值，而它的第二个参数`onCompletion`是一个可调用的对象。顾名思义，当提供的数据被完全写入时，`onCompletion`将被调用。

`bufferingWrite`方法的签名是我们对适合传递`Reactor.addWriter`的可写事件处理程序的期望。如上所述，它试图将任何缓冲的数据`send`到它传递的套接字，保存返回的指示写入量的数字。如果`send`引发一个`EAGAIN`异常，`bufferingWrite`抑制它并返回；否则，它会传播异常。在这两种情况下。`self._buffer`保持不变。

如果`send`成功，从`self._buffer`的开始处切掉与写入量相等的字节数，然后`bufferingWrite`返回。例如，如果`send`调用只写了 1024 个字节中的 952 个，`self_buffer`将包含最后的 73 个字节。

最后，如果缓冲区是空的，那么所有请求的数据都已经被写入，没有工作留给`BuffersWrites`实例去做。它请求反应器停止监视其套接字的可写事件，然后调用`onCompletion`,因为提供给它的数据已经被完全写入。注意，这个检查发生在独立于第一个`if self._buffer`语句的`if`语句中。前面的代码可能已经运行并清空了缓冲区；如果最终代码在附加到`if self._buffer`语句的`else`块中，它将不会运行，直到下一次反应器在这个套接字上检测到可写事件。为了简化资源管理，我们在这个方法中执行检查。

除了现在它通过它的`bufferingWrite`方法将数据委托给`BuffersWrites`之外，`write`函数看起来与我们之前的版本相似。最值得注意的是，`write`将*本身*传递给`BuffersWrites`作为`onCompletion`调用。这通过*间接递归*创建了与先前版本相同的循环效果。`write`从不直接调用自己，而是将自己传递给我们的*反应器*最终调用的对象。这种间接方式允许此序列继续进行，而不会溢出调用堆栈。

通过这些修改，我们的客户机-服务器程序不再阻塞。相反，它失败的另一个原因是:最终，`DATA`变得太大，不适合你的计算机的可用内存！下面是作者电脑中的一个例子:

```py
Client buffering 2 bytes to write.
Wrote 2 bytes
Client buffering 4 bytes to write.
Server received 2 bytes.
Wrote 4 bytes
...
Client buffering 2097152 bytes to write.
Server received 1024 bytes.
Wrote 1439354 bytes
Server received 1024 bytes.
Server received 1024 bytes.
....
Wrote 657798 bytes
Server received 1024 bytes.
Server received 1024 bytes.
....
Client buffering 268435456 bytes to write.
Traceback (most recent call last):
  File "example.py", line 76, in <module>
    loop.run()
  File "example.py", line 23, in run
    writeHandler(self, writable)
  File "example.py", line 57, in bufferingWrite
    self._onCompletion(reactor, sock)
  File "example.py", line 64, in write
    DATA.extend(DATA)
MemoryError

```

### 状态使程序变得复杂

尽管存在这个问题，但我们已经成功编写了一个事件驱动的网络程序，它使用非阻塞 IO 来控制套接字写入。然而，代码是混乱的:从`write`到`BuffersWrites`，然后是反应器，最后回到`write`的间接性模糊了出站数据的逻辑流，很明显，实现任何比简单的星号流更复杂的东西都将涉及扩展特设类和接口，超出它们的断点。例如，我们如何处理`MemoryError`？我们的方法无法扩展到实际应用中。

## 管理传输和协议的复杂性

使用非阻塞 I/O 编程无疑是复杂的。UNIX 权威 W. Richard Stevens 在其开创性的 *Unix 网络编程*系列的第一卷中写下了以下内容:

*   但是，考虑到结果代码的复杂性，使用非阻塞 I/O 编写应用值得吗？答案是否定的。

( *UNIX 网络编程，第 1 卷。第二版。第 446 页*

我们代码的复杂性似乎证明史蒂文斯是正确的。然而，正确的抽象可以将复杂性封装在一个可管理的接口中。我们的例子已经有了可重用的代码:任何写入套接字的新代码单元都需要使用核心逻辑`BuffersWrites`。我们已经*封装了*写非阻塞套接字的复杂性。基于这种认识，我们可以区分两个概念领域:

1.  *传输* : `BuffersWrites`管理将输出写入非阻塞套接字*的过程，而不考虑该输出*的内容。它可以发送照片，或者音乐，或者任何我们可以想象的东西，只要它可以用字节来表达。`BuffersWrites`是一个*传输*，因为它是*字节*的一种传输方式。传输封装了从套接字读取数据以及接受新连接的过程。它代表我们程序中动作的*原因*，是我们程序自身动作的*接收者*。

2.  *协议*:我们的示例程序用一个简单的算法生成数据，并且仅仅计算它接收到的数据。更复杂的程序可能会生成网页或将语音电话处理成文本。只要它们能接收和发送字节，它们就能与我们所描述的传输协同工作。它们还可以控制传输行为，比如在收到无效数据时关闭活动连接。电信领域描述了像这样的规则，这些规则定义了如何通过 T2 协议 T3 来交换数据。一个*协议*，然后*定义如何产生和处理输入和输出*。它封装了我们程序的*效果*。

### 反应器:使用传输

我们从改变我们的`Reactor`开始，在运输方面工作:

```py
import select
class Reactor(object):
    def __init__ (self):
        self._readers = set()
        self._writers = set()
    def addReader(self, transport):
        self._readers.add(transport)
    def addWriter(self, transport):
        self._writers.add(transport)
    def removeReader(self, readable):
        self._readers.discard(readable)
    def removeWriter(self, writable):
        self._writers.discard(writable)
    def run(self):
        while self._readers or self._writers:
            r, w, _ = select.select(self._readers,self._writers, [])
            for readable in r:
                readable.doRead()
            for writable in w:
                if writable in self._writers:
                    writable.doWrite()

```

我们的可读和可写事件处理程序以前是函数，现在是传输对象上的方法:`doRead`和`doWrite`。此外，反应堆不再跟踪插座-它直接`select`的运输。从反应堆的角度来看，传输接口包括:

1.  `doRead,`

2.  `doWrite,`

3.  使传输的状态对`select`可见的东西:一个`fileno()`方法，返回一个数字，`select`理解为对套接字的引用。

## 传输:使用协议

接下来，我们将通过回到我们的`read`和`write`函数来考虑一个协议实现。`read`职能有两个职责:

1.  计算套接字上接收的字节数。

2.  响应关闭的连接。

write 函数只有一个职责:对要写入的数据进行排队。

由此我们可以勾画出一个`Protocol`界面的初稿:

```py
class Protocol(object):
    def makeConnection(self, transport):
        ...
    def dataReceived(self, data):
        ...
    def connectionLost(self, exceptionOrNone):
        ...

```

我们将`read`的两个职责分成了两个方法:`dataReceived`和`connectionLost`。前者的签名是不言自明的，而后者接收一个参数:如果连接因为那个异常而被关闭(例如，因为`ECONNRESET`)，则接收一个异常对象；如果连接在没有异常的情况下被关闭(例如，因为被动关闭而具有空读取)，则接收`None`。注意，我们的协议接口缺少一个`write`方法。这是因为写入数据，包括传输字节，属于传输的范畴。因此，`Protocol`实例必须能够访问代表底层网络连接的传输，并且它将有一个`write`方法。两者之间的关联通过`makeConnection`发生，它接受一个传输作为它的参数。

为什么不将传输作为参数传递给`Protocol`的初始化器呢？一个单独的方法可能看起来笨拙，但它给我们提供了更大的灵活性；例如，您可以想象这个方法将如何允许我们引入`Protocol`缓存。此外，我们将看到，因为传输调用协议的`dataReceived`和`connectionLost`方法，所以它也必须与协议相关联。如果我们的`Transport`和`Protocol`类都需要它们的初始化式中的对等体，那么我们将会有一个循环关系来阻止它们被实例化。我们选择让我们的`Protocol`通过一个单独的方法接受它的传输来打破这个循环，因为它提供了灵活性。

### 用协议和传输打乒乓

这足以让我们编写一个更复杂的协议来实现这个新接口。我们之前的客户机-服务器示例只是让客户机向服务器发送越来越多的字节序列；我们可以增加这个，这样两个字节来回发送，直到一个可选的最大值，超过最大值的发送方关闭连接。

```py
class PingPongProtocol(object):
    def __init__ (self, identity, maximum=None):
        self._identity = identity
        self._received = 0
        self._maximum = maximum
    def makeConnection(self, transport):
        self.transport = transport
        self.transport.write(b'*')
    def dataReceived(self, data):
        self._received += len(data)
        if self._maximum is not None and self._received >= self._maximum:
            print(self._identity,"is closing the connection")
            self.transport.loseConnection()
        else:
            self.transport.write(b'*')
            print(self._identity,"wrote a byte")
    def connectionLost(self, exceptionOrNone):
        print(self._identity,"lost the connection:", exceptionOrNone)

```

初始化器接受一个用于标识协议实例的`identity`字符串，以及在终止连接之前可选的最大数据量。`makeConnection`将`PingPongProtocol`与其传输相关联，并通过发送单个字节开始交换。`dataReceived`记录接收到的数据量；如果总量超过可选的最大值，它告诉传输失去连接，或者等同于断开连接。否则，它通过发回一个字节来继续交换。最后，`connectionLost`在连接的协议方关闭时打印一条消息。

描述了一组行为，其复杂性远远超出了我们之前在非阻塞客户端-服务器应用方面的尝试。同时，它的实现反映了它之前的散文描述，而没有陷入非阻塞 I/O 的细节。我们已经能够增加我们的应用的复杂性，同时降低其独特的 I/O 管理的复杂性。我们将回头探讨这一问题的结果，但可以说，缩小我们的关注范围允许我们消除程序特定领域的复杂性。

在写入`Transport`之前，我们不能使用`PingPongProtocol`。然而，我们可以写一份`Transport`界面的初稿:

```py
class Transport(object):
    def __init__ (self, sock, protocol):
        ...
    def doRead(self):
        ...
    def doWrite(self):
        ...
    def fileno(self):
        ...
    def write(self):
        ...
    def loseConnection(self):
        ...

```

`Transport`初始化器的第一个参数是实例包装的套接字。这加强了`Transport'`对现在`Reactor`所依赖的套接字的封装。第二个参数是协议，当新数据可用时将调用其`dataReceived`,当连接关闭时将调用其`connectionLost`。`doRead`和`doWrite`方法与我们上面列举的反应器端传输接口相匹配。新方法`fileno`也是这个接口的一部分；一个正确实现了`fileno`方法的对象可以传递给`select`。我们将把对我们的`Transport`的`fileno`的调用代理到它所包装的套接字，使得从`select`的角度来看这两者无法区分。

`write`方法提供了接口，我们的`Protocol`依赖这个接口发送输出数据。我们还添加了`loseConnection`，一个新的`Protocol`端 API，它启动套接字的关闭，并代表我们的被动关闭`connectionLost`方法的主动关闭端。

我们可以通过在我们的`read`函数中吸收`BuffersWrites`和套接字处理来实现这个接口:

```py
import errno

class Transport(object):
    def __init__ (self, reactor, sock, protocol):
        self._reactor = reactor
        self._socket = sock
        self._protocol = protocol
        self._buffer = b "
        self._onCompletion = lambda:None
    def doWrite(self):
        if self._buffer:
            try:
                written = self._socket.send(self._buffer)
            except socket.error as e:
                if e.errno != errno.EAGAIN:
                    self._tearDown(e)
                return
            else:
                print("Wrote", written,"bytes")
                self._buffer = self._buffer[written:]
         if not self._buffer:
             self._reactor.removeWriter(self)
             self._onCompletion()
    def doRead(self):
        data=self._socket.recv(1024)
        if data:
            self._protocol.dataReceived(data)
        else:
            self._tearDown(None)
    def fileno(self):
        return self._socket.fileno()
    def write(self, data):
        self._buffer += data
        self._reactor.addWriter(self)
        self.doWrite()
    def loseConnection(self):
        if self._buffer:
            def complete():
                self.tearDown(None)
            self._onCompletion = complete
        else:
            self._tearDown(None)
    def _tearDown(self, exceptionOrNone):
        self._reactor.removeWriter(self)
        self._reactor.removeReader(self)

        self._socket.close()
        self._protocol.connectionLost(exceptionOrNone)
    def activate(self):
        self._socket.setblocking(False)
        self._protocol.makeConnection(self)
        self._reactor.addReader(self)
        self._reactor.addWriter(self)

```

`doRead`和`doWrite`反映了先前示例中的插座操作`read`和`write`功能以及`BuffersWrites`。`doRead`还将任何接收到的数据代理到协议的`dataReceived`方法，或者在接收到空读取时调用其`connectionLost`方法。最后，`fileno`通过使`Transport` s `select`能够完成`Reactor`要求的接口。

`write`方法像以前一样缓冲写操作，但是它不是将写操作委托给一个单独的类，而是调用它的兄弟`doWrite`方法将缓冲区刷新到套接字。如果缓冲区为空，对`loseConnection`的调用通过以下方式断开连接:

1.  从反应器中移除运输工具；

2.  关闭底层套接字以将其资源释放回操作系统；

3.  向协议的`connectionLost`发送`None`以表明由于被动关闭而导致连接丢失。

如果缓冲区*不为*空，则*有*数据要写入，因此`loseConnection`用一个*闭包*覆盖`_onCompletion`，该闭包按照与上述相同的过程断开连接。与`BuffersWrites`一样，`Transport._onCompletion`只有当我们的写缓冲区中的所有字节都被刷新到底层套接字时才会被调用。`loseConnection`对`_onCompletion`的使用确保了底层连接保持打开，直到所有数据都被写入。`_onCompletion`的默认值在`Transport`的初始化器中被设置为一个 lambda，没有任何效果。这确保了对`write`的多个调用可以重用底层连接。这些`write`和`loseConnection`的实现一起实现了`Protocol`所需的传输接口。

最后，`activate`通过以下方式激活传输:

1.  为非阻塞 I/O 准备包装的套接字；

2.  通过`Protocol.makeConnection`将`Transport`实例传递给它的协议；

3.  最后向反应器注册传输。

这通过包装连接生命周期的开始完成了`Transport`对其套接字的封装，其中结束已经被`loseConnection`封装。

在`Protocol`允许我们通过`PingPongProtocol`扩展我们的关注点并将行为添加到我们的应用中的地方，`Transport`已经围绕套接字的输入输出生命周期缩小了它的范围。reactor——我们的事件循环——从它们的起始套接字检测和调度事件，而协议包含我们需要的事件处理程序。`Transport`通过将套接字事件转换为协议方法调用并在这些方法调用之间实施*控制流*来进行协调；例如，它确保一个协议的`makeConnection`在它生命的开始被调用，而`loseConnection`在结束时被调用。这是对我们的特定客户机-服务器示例的另一个改进；我们将套接字的控制流完全集中在`Transport`内，而不是分散在不相关的函数和对象上。

### 具有协议和传输的客户端和服务器

我们可以通过定义一个子类型`Listener`来展示`Transport`的通用性，该子类型接受传入的连接并将它们与一个唯一的`PingPongProtocol`实例相关联:

```py
class Listener(Transport):
    def activate(self):
        self._reactor.addReader(self)
    def doRead(self):
        server, _ = self._socket.accept()
        protocol = PingPongProtocol("Server")
        Transport(self._reactor, server, protocol).activate()

```

侦听套接字不发出可写事件，所以我们覆盖了`activate`来只添加传输作为读取器。我们可读的事件处理程序`doRead`，必须接受一个新的客户端连接和协议，然后用一个激活的`Transport`将两者绑定在一起。

现在已经为由协议和传输提供支持的客户机-服务器示例做好了准备:

```py
listenerSock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
listenerSock.bind(('127.0.0.1',0))
listenerSock.listen(1)
clientSock = socket.create_connection(listenerSock.getsockname())

loop = Reactor()
Listener(loop, listenerSock, None).activate()
Transport(loop, clientSock, PingPongProtocol("Client", maximum=100)).activate()
loop.run()

```

两者将交换单个字节，直到客户端收到其最大值 100，之后客户端关闭连接:

```py
Server wrote a byte
Client wrote a byte
Wrote 1 bytes
Server wrote a byte
Wrote 1 bytes
Client wrote a byte
Wrote 1 bytes
Server wrote a byte
Wrote 1 bytes
Client wrote a byte
Wrote 1 bytes
Server wrote a byte

Server wrote a byte
Client is closing the connection
Client lost the connection: None
Server lost the connection: None

```

### Twisted 和反应器、协议和传输

我们已经走了很长一段路:从`select`开始，我们围绕一个事件循环及其处理程序开发了一组接口，它们清晰地划分了职责。我们的`Reactor`驱动我们的程序，`Transport`将套接字事件分派给在`Protocol`上定义的应用级处理程序。

我们的反应堆、运输机和协议显然是玩具。例如，`socket.create_connection`阻塞，我们还没有调查任何非阻塞的替代方案。事实上，`create_connection`暗示的底层 DNS 解析可能会自己阻塞！

然而，作为概念，它们已经可以认真使用了。反应器、传输和协议是 Twisted 事件驱动架构的基础。正如我们所看到的，它们的体系结构反过来又依赖于 I/O 多路复用和无阻塞的现实，从而使 Twisted 能够高效地运行。

然而，在我们探索 Twisted 本身之前，我们将把我们的例子作为一个整体来考虑，以评估事件驱动编程的优点和缺点。

## 事件驱动编程的价值

W.Richard Stevens 关于非阻塞 I/O 复杂性的告诫是对我们所探索的事件驱动编程范例的重要批评。然而，这不是唯一的缺点:我们的事件驱动范例在高 CPU 负载下表现不佳。

编写指数增长的字节序列的客户机-服务器示例自然会消耗大量内存，但也会消耗大量 CPU。原因是其缓冲区管理的幼稚:套接字根本不能接受大于特定大小的数据块。每次我们调用`send`的时候，调用`send`会把它复制到内核控制的内存位置。然后写入数据的一部分，然后我们切掉缓冲区的前端；因为`bytes`在 Python 中是不可变的，这意味着另一个副本。如果我们试图发送 N 个字节，我们将复制缓冲区一次，然后两次，一次又一次，直到 N。因为每次复制都意味着遍历缓冲区，所以这个过程的时间复杂度为 O( *n* <sup>*2*</sup> )。

Twisted 自己的缓冲机制性能更好，但代价是复杂性超出了事件驱动编程的可读介绍。然而，并不是所有计算要求高的任务都那么容易改进:蒙特卡罗模拟必须重复进行统计分析和随机采样；比较排序算法必须比较序列中的每一对元素；等等。

我们的事件驱动程序都执行多种逻辑行为——我们有一个客户端和一个服务器在一个进程中通信。这种通信同时发生*:在暂停并允许服务器取得少量进展之前，连接的客户端取得少量进展。客户端和服务器在任何时候都不是并行运行的*，就像它们在独立的 Python 解释器中一样，也许是在通过网络连接的独立计算机上。当我们简单的缓冲区管理执行一个冗长的拷贝时，在这个过程完成之前不会有任何进展，而如果客户机和服务器运行在不同的计算机上，服务器可以接受新的连接，而客户机则费力地来回移动字节。如果我们在我们的过程中运行一个计算要求很高的算法，我们的反应器不能调用`select`来发现新的事件以对其做出反应，直到这个算法完成之后。**

 **因此，事件驱动编程不适合计算要求高的任务。幸运的是，许多任务对输入和输出的要求比计算更高。网络服务器就是一个典型的例子；一个聊天服务器可能有成千上万的用户，但是在任何时候只有一小部分是活跃的(而且通常在你寻求帮助的时候是不活跃的！).因此，事件驱动编程仍然是网络中一个强大的范例。

事件驱动编程有一个特别的优势，可以弥补这个缺点:它强调*原因*和*效果*。一个事件的产生代表一个原因，而那个事件的处理程序代表预期的结果。

我们在`Transport`和`Protocol`中对这种划分进行了整理:传输表示动作的*原因*——一些输入或套接字输出——而协议封装了*效果*。我们的`PingPongProtocol`通过一个清晰的接口与其传输进行交互，该接口将处理程序暴露给更高级别的事件——原因——比如传入字节的到达或连接的结束。然后，它从这些原因中产生*效果*，这又可能导致新的*原因*，例如将数据写入传输。两者之间的区别是由各自的接口决定的。

这意味着我们可以用一个传输替换另一个，并通过调用表示预期效果的方法来模拟我们的协议的执行。这将我们的客户机-服务器的核心变成了一个可测试的代码单元。

考虑一个构建在`BytesIO`上的传输实现，它只实现了`Transport`接口的`Protocol`端:

```py
import io

class BytesTransport(object):

    def __init__ (self, protocol):
        self.protocol = protocol
        self.output = io.BytesIO()
    def write(self, data):
        self.output.write(data)
    def loseConnection(self):
        self.output.close()
        self.protocol.connectionLost(None)

```

我们可以用它来为我们的`PingPongProtocol`编写一个单元测试套件:

```py
import unittest

class PingPongProtocolTests(unittest.TestCase):
    def setUp(self):
        self.maximum = 100
        self.protocol = PingPongProtocol("client", maximum=self.maximum)
        self.transport = BytesTransport(self.protocol)
        self.protocol.makeConnection(self.transport)
    def test_firstByteWritten(self):
        self.assertEqual(len(self.transport.output.getvalue()), 1)
    def test_byteWrittenForByte(self):
        self.protocol.dataReceived(b"*")
        self.assertEqual(len(self.transport.output.getvalue()), 2)
    def test_receivingMaximumLosesConnection(self):
        self.protocol.dataReceived(b"*" * self.maximum)
        self.assertTrue(self.transport.output.closed)

```

这个测试断言了我们为`PingPongProtocol`设置的需求，而没有设置任何套接字或执行任何实际的 I/O。我们可以测试我们程序的*效应*，而没有具体的*原因*。相反，我们通过用字节调用我们的协议实例的`dataReceived`方法来模拟可读事件，而协议通过在我们的字节传输上调用`write`来生成可写事件，并通过调用`loseConnection`来生成关闭请求。

Twisted 努力分开原因和结果。如前所述，最明显的好处是可测试性。为事件驱动的 Twisted 程序编写全面的测试更容易，因为协议和传输之间有基本的区别。事实上，Twisted 将责任之间的这种区别作为设计中的一门深刻课程，从而产生了其庞大且有时晦涩难懂的词汇。让这么多东西明确地分离对象需要大量的名称。

我们现在准备用 Twisted 编写一个事件驱动的程序。我们将会遇到我们在玩具例子中遇到的同样的设计问题，而编写这些玩具的经验将会阐明 Twisted 为解决这些问题所提供的策略。

## Twisted 的现实世界

我们从实现我们的`PingPongProtocol`客户机和服务器开始探索 Twisted:

```py
from twisted.internet import protocol, reactor

class PingPongProtocol(protocol.Protocol):
    def __init__ (self):
        self._received = 0
    def connectionMade(self):
        self.transport.write(b'*')
    def dataReceived(self, data):
        self._received += len(data)
        if self.factory._maximum is not None and self._received >= self.factory._maximum:
            print(self.factory._identity, "is closing the connection")
            self.transport.loseConnection()
        else:
            self.transport.write(b'*')
            print(self.factory._identity,"wrote a byte")
    def connectionLost(self, exceptionOrNone):
        print(self.factory._identity,"lost the connection:", exceptionOrNone)

class PingPongServerFactory(protocol.Factory):
    protocol = PingPongProtocol
    _identity = "Server"

    def __init__ (self, maximum=None):
        self._maximum = maximum

class PingPongClientFactory(protocol.ClientFactory):
    protocol = PingPongProtocol
    _identity = "Client"

    def __init__ (self, maximum=None):
        self._maximum = maximum

    listener=reactor.listenTCP(port=0,
                               factory=PingPongServerFactory(),
                               interface='127.0.0.1')
    address = listener.getHost()
    reactor.connectTCP(host=address.host,
                       port=address.port,
                       factory=PingPongClientFactory(maximum=100))
    reactor.run()

```

我们的`PingPongProtocol`类与我们的玩具实现几乎相同。有三个变化:

1.  我们继承自`twisted.internet.protocol.Protocol`。这个类提供了重要功能的有用的默认实现。在最初设计 Twisted 的传输和协议时，继承是一种流行的代码重用方法。围绕公共和私有 API 的困难以及关注点的分离已经正确地导致了它的受欢迎程度的下降。对继承缺点的完整讨论超出了本章的范围，但是我们不建议编写依赖继承的新 API！

2.  我们用`connectionMade`替换了`makeConnection`，这是一个事件处理程序，当底层连接就绪时，它会 Twisted 调用。Twisted 的`Protocol`类为我们实现了`makeConnection`，并留下了`connectionMade`作为我们可以填充的存根。实际上，我们不希望改变传输与协议的关联方式，但是我们经常希望代码在连接就绪后立即运行。这个处理程序提供了这样做的方法。

3.  最大字节数和协议标识不再是实例变量；相反，它们是新的`factory`实例变量的属性。

*协议工厂*协调协议的创建及其与传输的绑定。这是我们第一个 Twisted 将责任本地化到类的例子。协议工厂有两种基本类型:服务器和客户端。顾名思义，一个管理服务器端协议的创建，而另一个管理客户端协议的创建。两者都通过不带参数地调用它们的`protocol`属性来创建协议实例。这就是为什么`PingPongProtocol`的初始化器不接受参数。

`PingPongServerFactory`子类化`twisted.internet.protocol.Factory`并将它的`_identity`属性设置为`"Server."`它的初始化器接受反应器作为参数和可选的最大值。然后，它依赖其超类的实现来创建其协议的实例——在类级别设置为`PingPongProtocol`——并将它们与自身相关联。这就是为什么`PingPongProtocol`实例有一个`factory`属性:`Factory`默认为我们创建。

`PingPongClientFactory`子类化`twisted.internet.protocol.ClientFactory`,并将其`_identity`属性设置为`"Client."`,其他方面与`PingPongServerFactory`相同。

工厂为存储所有协议实例共享的状态提供了一个方便的地方。因为协议实例对于连接来说是唯一的，所以当连接存在时，它们就不再存在，并且不能自己保持状态。因此，像我们的最大允许值和我们的协议客户机或服务器标识字符串这样的设置转移到它们的工厂遵循 Twisted 中的一个常见模式。

`reactor`公开了`listenTCP`和`connectTCP`方法，它们将工厂与服务器和客户端连接相关联。`listenTCP`返回一个`Port`对象，其`getHost`方法类似于`socket.getsockname`。然而，它不是返回一个元组，而是返回一个`twisted.internet.address.IPv4Address`的实例，该实例又具有方便的`host`和`port`属性。

最后，我们通过调用`run`来启动`reactor`，就像我们对玩具实现所做的那样。迎接我们的是类似于我们的玩具实现打印的输出:

```py
Client wrote a byte
Server wrote a byte
Client wrote a byte
Server wrote a byte
Client wrote a byte
Server wrote a byte
Client wrote a byte
Server wrote a byte
Client is closing the connection
Client lost the connection: [Failure instance: ...: Connection was closed cleanly.
]
Server lost the connection: [Failure instance: ...: Connection was closed cleanly.
]

```

抛开传递给`connectionLost`的`Failure`对象(我们将在 Twisted 中讨论异步编程)不谈，这个输出似乎证明了我们的新实现的行为与旧实现的行为相匹配。

然而，通过修改我们的协议测试，我们可以做得比比较输出更好:

```py
from twisted.trial import unittest
from twisted.test.proto_helpers import StringTransportWithDisconnection, MemoryReactor

class PingPongProtocolTests(unittest.SynchronousTestCase):
    def setUp(self):
        self.maximum = 100
        self.reactor = MemoryReactor()
        self.factory = PingPongClientFactory(self.reactor,self.maximum)
        self.protocol = self.factory.buildProtocol(address.IPv4Address(
            "TCP","localhost",1234))
        self.transport = StringTransportWithDisconnection()
        self.protocol.makeConnection(self.transport)
        self.transport.protocol = self.protocol
    def test_firstByteWritten(self):
        self.assertEqual(len(self.transport.value()), 1)
    def test_byteWrittenForByte(self):
        self.protocol.dataReceived(b"*")
        self.assertEqual(len(self.transport.value()), 2)
    def test_receivingMaximumLosesConnection(self):
        self.protocol.dataReceived(b"*" * self.maximum)
        self.assertFalse(self.transport.connected)

```

Twisted 有自己的测试基础设施，我们将在异步编程的讨论中涉及到它；现在，我们可以将`SynchronousTestCase`视为等同于标准库的`unittest.TestCase`。我们的`setUp`方法现在构建了一个`MemoryReactor`赝品，它代替了我们真正的反应堆。它将其传递给`PingPongClientFactory`，然后通过调用从`ClientFactory`继承的`buildProtocol`方法构建一个`PingPongProtocol`客户端。这又需要一个地址参数，为此我们提供了另一个假参数。然后我们使用 Twisted 的内置`StringTransportWithDisconnection`，它的行为和接口与我们的 toy `BytesTransport`实现一致。Twisted 称之为`StringTransport`，因为在编写它的时候，所有发布的 Python 版本都有一个默认的字符串类型`bytes`。在 Python 3 的世界中，`StringTransport`已经成为一个误称，因为它仍然必须以字节为单位工作。

我们的测试方法调整到`StringTransportWithDisconnection`的接口:`value`返回写入的内容，而`connected`在协议调用`loseConnection`时变成`False`。

客户端和服务器的 Twisted 实现清楚地表明了 Twisted 和我们的示例代码之间的相似之处:反应器多路复用来自套接字的事件，并通过传输将它们分派给协议，然后协议可以通过它们的传输创建新的事件。

虽然这种动态形成了 Twisted 的事件驱动架构的核心，并通知其设计决策，但它是相对较低的级别。许多程序从不实现自己的`Protocol`子类。接下来，我们转向一种事件，它是许多 Twisted 程序中直接使用的模式和 API 的基础。

## 时间上的事件

到目前为止，我们看到的所有事件都源于输入，比如用户点击按钮或新数据到达套接字。程序必须经常安排动作在未来某个时间点运行，与任何输入分开。考虑一个心跳:每 30 秒左右，网络应用将向其连接写入一个字节，以确保远程终端不会因为不活动而关闭它们。

Twisted 提供了一个底层接口，通过`reactor.callLater`来安排未来的行动。我们通常不直接调用这个 API，但是现在将这样做来解释它是如何工作的。

```py
from twisted.internet import reactor

reactor.callLater(1.5, print,"Hello from the past.")
reactor.run()

```

`reactor.callLater`接受数字延迟和可调用。当调用 callable 时，任何其他位置或关键字参数都会传递给它。运行该程序将不会产生任何输出，直到大约 1.5 秒后，此时`Hello from the past`将会出现。

`reactor.callLater`返回一个可以取消的`DelayedCall`实例:

```py
from twisted.internet import reactor

call = reactor.callLater(1.5, print,"Hello from the past.")
call.cancel()
reactor.run()

```

这个程序没有输出，因为`DelayedCall`在反应器运行它之前就被取消了。

显然`reactor.callLater`发出一个事件，表明指定的时间已经过去，并运行它作为该事件的处理程序接收的可调用程序。然而，这种情况发生的机制还不太清楚。

幸运的是，实现基本上很简单，这也说明了为什么延迟只是近似值。回想一下，`select`接受一个可选的超时参数。当我们希望`select`立即告诉我们已经生成了什么事件，而不是等待新的事件时，我们用 0 作为超时来调用它。除了基于套接字的事件之外，我们现在可以使用这个超时来复用基于时间的事件:为了确保我们的`DelayedCall`运行，我们可以调用`select`，超时时间等于应该调度的下一个`DelayedCall`的延迟，也就是时间上最近的那个。

想象一个包含以下内容的程序:

```py
reactor.callLater(2, functionB)
reactor.callLater(1, functionA)
reactor.callLater(3, functionC)
reactor.run()

```

reactor 将`DelayedCall`记录在一个 min-heap 中，按照它计划运行的挂钟时间排序:

```py
def callLater(self, delay, f,*args,**kwargs):
    self._pendingCalls.append((time.time()+delay, f, args, kwargs)
    heapq.heapify(self._pendingCalls)

```

如果第一个`reactor.callLater`发生在时间 *t* ，并且每个调用不占用时间，那么在所有三个调用之后，`pendingCalls`将如下所示:

```py
[
    (t+1, <DelayedCall: functionA>),
    (t+2, <DelayedCall: functionB>),
    (t+3, <DelayedCall: functionB>),
]

```

向堆中添加一个元素的时间复杂度为 O(log *n* )，因此重复的`callLater`调用的总最坏情况时间复杂度为 O( *n* log *n* )。如果反应器改为排序`_pendingCalls`，重复的`callLater`调用将取 O(*n*)* O(*n*log*n*)= O(*n*<sup>*2*</sup>)。

现在，在反应堆进入`select,`之前，它检查是否有任何未决的`DelayedCall`s；如果有，它提取堆的顶部元素，并使用其目标运行时间和当前时间之差作为`select`的超时。然后，在处理任何套接字事件之前，它从堆中弹出每个时间已过的元素并运行它，跳过取消的调用。如果没有未决的`DelayCall`，反应器调用`select`，超时`None`，表示没有超时。

```py
class Reactor(object):
    ...
    def run(self):
        while self.running:
            if self._pendingCalls:
                targetTime, _ = self._pendingCalls[0]
                delay=targetTime-time.time()
            else:
                targetTime = None
            r, w, _ = select.select(self.readers,self.writers, [], targetTime)
            now = time.time()
            while self._pendingCalls and (self._pendingCalls[0][0] <= now):
                targetTime, (f, args, kwargs) = heapq.heappop()
                if not call.cancelled:
                    f(*args,**kwargs)
            ...

```

在我们的三个`reactor.callLater`调用中，`functionA`的延迟最短，因此位于`pendingCalls`堆的顶部。如果我们的反应器的`run`循环随后立即开始(即，也在时间 *t* )，那么`delay`变量将为( *t* + 1) - *t* = 1，并且`select`调用将在不超过一秒钟后返回。现在，`time.time`返回 *t* + 1，所以`functionA`的`DelayedCall`，从而`functionA`运行。然而，`functionB`和`functionC`的`DelayedCall`仍然留在将来，因此内部`while`循环结束，过程再次开始。

该实现揭示了为什么`DelayedCall`在延迟过后不立即运行:它们的调用取决于它们在`pendingCalls`堆中的位置以及前面的`DelayedCall`需要多长时间来完成。如果`functionA`运行的时间超过一秒钟，`functionB`就会运行得比截止时间晚。这对于延迟相同时间的`DelayedCall` s 来说尤其可能。

### 使用`LoopingCall`重复事件

足以实现我们的心跳。我们可以定义一个用自身调用`callLater`的函数，然后通过直接调用该函数一次来启动间接递归:

```py
def f(reactor, delay)
    reactor.callLater(delay, f, reactor, delay)
f(reactor,1.0)

```

这是可行的，但是很笨拙。在对`f`的初始呼叫之后，我们不能访问代表对`f`的下一次呼叫的`DelayedCall`，所以如果对方终止连接，我们不能轻易取消它。我们可以手动跟踪这些呼叫，但幸运的是，Twisted 提供了一个方便的包装器`callLater`，为我们处理这一切:`twisted.internet.task.LoopingCall`。下面是一个使用`LoopingCall`来实现心跳的协议:

```py
from twisted.internet import protocol, task

class HeartbeatProtocol(protocol.Protocol):
    def connectionMade(self):
        self._heartbeater = task.LoopingCall(self.transport.write, b"*")
        self._heartbeater.clock = self.factory._reactor
        self._heartbeater.start(interval=30.0)
    def connectionLost(self):
        self._heartbeater.stop()

class HeartbeatProtocolFactory(protocol.Factory):
    protocol = HeartbeatProtocol
    def __init__ (self, reactor):
        self._reactor = reactor

```

该协议创建了一个新的`LoopingCall`实例，它将在连接建立时向协议的传输写入一个星号。然后它用工厂的反应堆替换了`LoopingCall`的时钟；我们很快就会看到，这种间接方式有助于测试。最后，该协议以 30 秒的间隔启动`LoopingCall`，这样大约每 30 秒它就会用一个星号调用`transport.write`。`LoopingCall`从什么时候开始计时 30 秒？它是从 0 开始计数，在这种情况下应该立即调用它的函数，还是从 1 开始计数，在这种情况下应该等待整整 30 秒？答案取决于程序员。`LoopingCall.start`的第二个可选参数`now`决定了该函数是应该作为对`start`的调用的一部分被调用，还是在一个完整的间隔过去之后被调用。它默认为`True`，所以我们的心跳会立即向传输写一个星号。

从工厂取回反应堆使得`HeartbeatProtocol`和`PingPongProtocol`一样容易测试:

```py
from twisted.trial import unittest
from twisted.internet import main, task
from twisted.test.proto_helpers import StringTransportWithDisconnection

class HeartbeatProtocolTests(unittest.SynchronousTestCase):
    def setUp(self):
        self.clock = task.Clock()
        self.factory = HeartbeatProtocolFactory(self.clock)
        self.protocol = self.factory.buildProtocol(address.IPv4Address(
            "TCP","localhost",1234))
        self.transport = StringTransportWithDisconnection()
        self.protocol.makeConnection(self.transport)
        self.transport.protocol = self.protocol
    def test_heartbeatWritten(self):
        self.assertEqual(len(self.transport.value()), 1)
        self.clock.advance(60)
        self.assertEqual(len(self.transport.value()), 2)
    def test_lostConnectionStopsHeartbeater(self):
        self.assertTrue(self.protocol._heartbeater.running)
        self.protocol.connectionLost(main.CONNECTION_DONE)
        self.assertFalse(self.protocol._heartbeater.running)

```

`HeartbeatProtocolTest.setUp`与`PingPongProtocolTests.setUp`几乎相同，除了它用`twisted.internet.task.Clock`代替`MemoryReactor`。`Clock`，顾名思义，提供了一个反应器的时间相关接口的实现。最重要的是，它有一个`callLater`方法:

```py
>>> from twisted.internet.task import Clock
>>> clock = Clock()
>>> clock.callLater(1.0, print,"OK")

```

因为它们旨在单元测试中使用，`Clock`实例自然没有自己的`select`循环。我们可以通过调用`advance`来模拟`select`超时的终止:

```py
>>> clock.advance(2)
OK

```

`test_heartbeatWritten`调用`advance`使其协议的`LoopingCall`写入一个字节。这类似于`PingPongProtocolTests.test_byteWrittenForByte`对其协议的`dataReceived`的调用；两者都模拟了反应堆在这些测试之外管理的事件的发生。

Twisted 的事件驱动编程方法依赖于清晰描述的接口，如`Protocol`和`Clock`的接口。然而，到目前为止，我们都认为每个接口的本质是理所当然的:我们怎么知道`Clock`或`MemoryReactor`可以取代测试套件中的真实反应器呢？我们可以通过探索 Twisted 用来管理其接口的工具来回答这个问题。

## 与 zope.interface 的事件接口

Twisted 使用一个名为`zope.interface`的包来形式化它的内部接口，包括那些描述它的事件驱动范例的接口。

Zope 是一个古老但仍然活跃的项目，已经产生了几个 web 应用框架，其中最老的是在 1998 年首次公开发布的。许多技术起源于 Zope，并被用于其他项目。Twisted 使用 Zope 的*接口*包来定义它的接口。

对`zope.interface`的完整解释超出了本书的范围。然而，接口在测试和文档中起着重要的作用，所以我们通过研究前面例子中使用的 Twisted 类的接口来介绍它们。

我们首先询问`Clock`的一个实例，它*提供了什么接口*:

```py
>>> from twisted.internet.task import Clock
>>> clock = Clock()
>>> from zope.interface import providedBy
>>> list(providedBy(clock))
[<InterfaceClass twisted.internet.interfaces.IReactorTime>]

```

首先，我们创建一个`Clock`的实例。然后我们从`zope.interface`包中检索`providedBy`；因为 Twisted 本身依赖于`zope.interface`，所以我们可以在交互会话中使用它。在我们的`Clock`实例上调用`providedBy`会返回它提供的*接口*的一个 iterable。

与其他语言的接口不同，`zope.interface`的接口可以是*实现的*或*提供的*。符合接口*的单个对象提供*该接口，而*创建*那些提供接口的对象*实现*该接口。这种微妙的区别与 Python 的“鸭子打字”相匹配。一个接口定义可能描述一个`call`方法，并因此应用于一个用`def`或`lambda`创建的函数对象。这些语法元素不能被标记为我们接口的*实现者*，但是功能对象本身可以说是*提供了*它。

一个*接口*是`zope.interface.Interface`的子类，它使用一个特殊的 API 来描述所需的方法和它们的签名以及属性。下面是我们的`Clock`提供的`twisted.internet.interfaces.IReactorTime`接口的摘录:

```py
class IReactorTime(Interface):
    """
    Time methods that a Reactor should implement.
    """

def callLater(delay, callable,*args,**kw):
    """
    Call a function later.

    @type delay:  C{float}
    @param delay: the number of seconds to wait.

    @param callable: the callable object to call later.

    @param args: the arguments to call it with.

    @param kw: the keyword arguments to call it with.

    @return: An object which provides L{IDelayedCall} and can be used to
             cancel the scheduled call, by calling its C{cancel()} method.
             It also may be rescheduled by calling its C{delay()} or
             C{reset()} methods.
    """

```

注意，`callLater`“方法”没有`self`参数。这是接口不能实例化的结果。它也没有主体，而是通过只提供一个 docstring 来满足 Python 的函数定义语法。不像抽象类，比如那些由标准库的`abc`模块提供的，它们也不能包含任何实现代码。相反，它们只是作为描述对象功能子集的标记而存在。

Zope 提供了一个名为`verifyObject`的助手，如果一个对象没有提供接口，它会抛出一个异常:

```py
>>> from zope.interface.verify import verifyObject
>>> from twisted.internet.interfaces import IReactorTime
>>> verifyObject(IReactorTime, clock)
True
>>> verifyObject(IReactorTime, object()))
Traceback (most recent call last):
  File"<stdin>", line1, in <module>
  ...
zope.interface.exceptions.DoesNotImplement: An object does not implement interface<Interface

```

我们可以用这个来确认反应器提供了与`Clock`实例相同的`IReactorTime`接口:

```py
>>> from twisted.internet import reactor
>>> verifyObject(IReactorTime, reactor) True

```

稍后当我们编写自己的接口实现时，我们将回到`verifyObject`。不过现在，只要知道我们可以在任何依赖`IReactorTime.callLater`的地方用`Clock`实例替换反应器就足够了。一般来说，如果我们知道一个对象所提供的接口包含了我们所依赖的方法或属性，我们就可以用其他提供相同接口的对象来替换这个对象。虽然我们可以用`providedBy`交互地发现一个对象提供的接口，但是 Twisted 的在线文档对接口有特殊的支持。图 [1-2](#Fig2) 描述了 Twisted 网站上`Clock`的文档。

![img/455189_1_En_1_Fig2_HTML.jpg](img/455189_1_En_1_Fig2_HTML.jpg)

图 1-2

`twisted.internet.task.Clock`文档。虚线框突出显示了到`IReactorTime`接口的链接。

由`Clock`类实现的接口在虚线矩形中突出显示。单击每一个都可以看到该接口的文档，其中包括所有已知实现者和提供者的列表。如果您知道对象是什么，那么您可以通过访问它的文档来确定它的接口。

我们接下来讨论一个问题，这个问题的 Twisted 解决方案涉及到定义接口的实现者。

## 事件驱动程序中的流量控制

`PingPongProtocol`不同于我们为上一个非 Twisted 事件驱动的示例编写的流协议:`PingPongProtocol`中的每一端都写入一个字节来响应接收到的字节，而流协议让客户端向服务器发送越来越大的字节序列，当服务器不堪重负时暂停其写入。调整发送方的写入速率以匹配接收方的读取速率被称为*流量控制*。

当与事件驱动的编程相结合时，非阻塞 I/O 使我们能够编写在任何给定时间可以响应许多不同事件的程序。*同步* I/O，就像我们看到的根据`sendall`实现的流客户端协议，暂停或*阻塞*我们的程序，阻止它做任何事情，直到 I/O 操作完成。虽然这增加了并发性的难度，但它使流控制变得更加容易:超过其读取器速度的编写器会被操作系统暂停，直到读取器接受挂起的数据。在我们的流客户端中，这导致了死锁，因为慢速读者运行在由于写得太快而暂停的同一进程中，因此永远无法跟上。更常见的情况是，读取器和写入器运行在不同的进程中，如果不是在不同的机器上，它们的同步、阻塞 I/O 自然提供了流控制。

然而，在网络应用中很少遇到简单的阻塞 I/O。即使是最简单的也必须为每个连接同时管理两件事:数据通信和与每个 I/O 操作相关的超时。Python 的`socket`模块允许程序员在`recv`和`sendall`操作上设置这些超时，但在幕后这是通过调用带有超时的`select`来实现的！

我们有实现流控制所必需的事件。`select`通知我们可写事件，而`EAGAIN`表明套接字的发送缓冲区已满，从而间接表明接收者不堪重负。我们可以组合这些来暂停和恢复写入程序，并实现类似于阻塞 I/O 所提供的流控制。

## 流控制与生产者和消费者纠缠在一起

Twisted 的流量控制系统有两个组成部分:*生产者*和*消费者*。生产者通过调用消费者的`write`方法向消费者写入数据。消费者*包装*生产者；每个消费者可以与一个生产者相关联。这种关系确保了消费者可以访问其生产者，因此它可以通过调用生产者的某些方法来调节数据流，从而对生产者施加反压力。常见的传输，比如绑定到像我们的`PingPongProtocol`这样的协议的 TCP 传输，既可以是消费者也可以是生产者。

我们通过重新实现我们预先 Twisted 的流客户端示例来探索生产者和消费者之间的交互。

### 推动生产者

我们从客户的制作人开始:

```py
from twisted.internet.interfaces import IPushProducer
from twisted.internet.task import LoopingCall
from zope.interface import implementer

@implementer(IPushProducer)
class StreamingProducer(object):
    INTERVAL=0.001
    def __init__ (self, reactor, consumer):
        self._data = [b"*", b"*"]
        self._loop = LoopingCall(self._writeData, consumer.write)
        self._loop.clock = reactor
    def resumeProducing(self):
        print("Resuming client producer.")
        self._loop.start(self.INTERVAL)
    def pauseProducing(self):
        print("Pausing client producer.")
        self._loop.stop()
    def stopProducing(self):
        print("Stopping client producer.")
        if self._loop.running:
            self._loop.stop()
    def _writeData(self, write):
        print("Client producer writing", len(self._data),"bytes.")
        write(b"".join(self._data))
        self._data.extend(self._data)

```

我们的生产者`StreamingProducer`，实现`twisted.internet.interfaces.IPushProducer`。该接口描述了不断向其消费者写入数据直到暂停的生产者。`StreamingProducer`上的以下方法满足`IPushProducer`接口:

*   `resumeProducing`:恢复或启动向消费者写入数据的过程。因为我们的实现通过在每次写入后将一个字节序列加倍来生成数据，所以它需要某种类型的循环来向其消费者提供连续的流。简单的`while`循环是行不通的:如果不将控制权交还给反应器，程序就不能处理新的事件，直到循环终止。事件驱动的程序(如 web 浏览器)在大文件上传期间会有效地暂停其执行。`StreamingProducer`通过一个`LoopingCall`实例将写循环委托给反应器来避免这种情况，因此它的`resumeProducing`方法启动了那个`LoopingCall`。一毫秒的间隔是任意低的。我们的生产者不能比这更快地写入数据，所以间隔是延迟的来源，一毫秒可以接受地最小化它。

*   `pauseProducing`:暂停向消费者写入数据的过程。消费者称这表明它已经不堪重负，无法接受更多的数据。在我们的实现中，停止底层的`LoopingCall`就足够了。当底层资源可以接受更多数据时，消费者可以稍后调用`resumeProducing`。这个`resumeProducing`和`pauseProducing`调用的循环构成了流量控制。

*   `stopProducing`:这终止了数据的产生。这与`pauseProducing`不同，因为在调用`stopProducing`之后，消费者再也不能调用`resumeProducing`来接收更多的数据。最明显的是，当一个套接字连接被关闭时，它被调用。`StreamingProducer`的实现与`pauseProducing`方法的唯一不同之处在于，它必须首先检查循环调用是否正在运行。这是因为当生产者已经暂停时，消费者可能请求不再写入数据。更复杂的推送生产者将执行额外的清理；例如，从一个文件传输数据的生产者需要在这里关闭该文件，以将其资源释放回操作系统。

请注意，`IPushProducer`并没有指定*它的实现者如何*向消费者写入数据，甚至如何访问数据。这使得界面更加灵活，但也使其更难实现。`StreamingProducer`遵循一种典型的模式，在其初始化器中接受消费者。我们将很快介绍完整的消费者接口，但是现在，知道消费者必须提供一个`write`方法就足够了。

我们可以测试`StreamingProducer`实现了`IPushProducer`的预期行为:

```py
from twisted.internet.interfaces import IPushProducer
from twisted.internet.task import Clock
from twisted.trial import unittest
from zope.interface.verify import verifyObject

class FakeConsumer(object):
    def __init__ (self, written):
        self._written = written
    def write(self, data):
        self._written.append(data)

class StreamingProducerTests(unittest.TestCase):
    def setUp(self):
        self.clock = Clock()
        self.written = []
        self.consumer = FakeConsumer(self.written)
        self.producer = StreamingProducer(self.clock,self.consumer)
    def test_providesIPushProducer(self):
        verifyObject(IPushProducer,self.producer)
    def test_resumeProducingSchedulesWrites(self):
        self.assertFalse(self.written)
        self.producer.resumeProducing()
        writeCalls = len(self.written)
        self.assertEqual(writeCalls,1)
        self.clock.advance(self.producer.INTERVAL)
        newWriteCalls = len(self.written)
        self.assertGreater(newWriteCalls, writeCalls)
    def test_pauseProducingStopsWrites(self):
        self.producer.resumeProducing()

        writeCalls = len(self.written)
        self.producer.pauseProducing()
        self.clock.advance(self.producer.INTERVAL)
        self.assertEqual(len(self.written), writeCalls)
    def test_stopProducingStopsWrites(self):
        self.producer.resumeProducing()
        writeCalls = len(self.written)
        self.producer.stopProducing()
        self.clock.advance(self.producer.INTERVAL)
        self.assertEqual(len(self.written), writeCalls)

```

`FakeConsumer`接受一个列表，每个`write`调用都会将收到的数据附加到该列表中。这允许测试套件断言`StreamingProducer`已经在预期的时候调用了它的消费者的`write`方法。

`test_providesIPushProducer`确保`StreamingProducer`定义了`IPushProducer`要求的方法。如果没有，这个测试将通过`zope.interface.exceptions.DoesNotImplement`失败。像这样断言实现满足其接口的测试在开发和重构中是一个有用的高通过滤器。

`test_resumeProducingSchedulesWrites`断言调用`resumeProducing`意味着向消费者写入数据，并且每次经过指定的时间间隔，都会写入更多的数据。`test_pauseProducingStopsWrites`和`test_stopProducingStopsWrites`都断言相反的情况:调用`pauseProducing`和`stopProducing`防止在每个间隔过去后发生进一步的写操作。

### 顾客

`StreamingProducer`放出数据却无处安放。为了完成我们的流媒体客户端，我们需要一个*消费者*。`StreamingProducer`的初始化器清楚地表明，消费者的接口必须提供一个`write`方法，概述表明，额外的消费者方法管理与生产者的交互。`twisted.internet.interfaces.IConsumer`要求实施者实施三种方法:

*   `write`:接受来自生产者的数据。这是在我们上面的测试中由`FakeConsumer`提供的唯一方法，因为它是`IConsumer`接口`IPushProducer`调用的唯一部分。

*   `registerProducer`:这将生产者与消费者关联起来，确保它可以调用生产者的`resumeProducing`和`pauseProducing`来调节数据流，调用`stopProducing`来终止数据流。这接受了两个论点:生产者和一面`streaming`旗帜。我们稍后将解释这第二个论点的目的；现在，知道我们的流媒体客户端会将此设置为`True`就足够了。

*   这就把生产者和消费者分开了。一个消费者可能在其一生中接受来自多个生产者的数据；再考虑一个 web 浏览器，它可能通过单个连接向服务器上传多个文件。

`IConsumer`实现者和传输者都公开了`write`方法，这并不是巧合；如上所述，绑定到连接协议的 TCP 传输是一个消费者，我们可以向其注册一个`StreamingProducer`实例。我们可以修改我们的`PingPongProtocol`示例，在成功连接后用其底层传输注册`StreamingProducer`:

```py
from twisted.internet import protocol, reactor
from twisted.internet.interfaces import IPushProducer
from twisted.internet.task import LoopingCall
from zope.interface import implementer

@implementer(IPushProducer)
class StreamingProducer(object):
    INTERVAL=0.001
    def __init__ (self, reactor, consumer):
        self._data = [b"*", b"*"]
        self._loop = LoopingCall(self._writeData, consumer.write)
        self._loop.clock = reactor
    def resumeProducing(self):
        print("Resuming client producer.")
        self._loop.start(self.INTERVAL)
    def pauseProducing(self):
        print("Pausing client producer.")
        self._loop.stop()
    def stopProducing(self):
        print("Stopping client producer.")

        if self._loop.running:
            self._loop.stop()
    def _writeData(self, write):
        print("Client producer writing", len(self._data),"bytes.")
        write(b"".join(self._data))
        self._data.extend(self._data)

class StreamingClient(protocol.Protocol):
    def connectionMade(self):
        streamingProducer = StreamingProducer(
            self.factory._reactor,self.transport)
        self.transport.registerProducer(streamingProducer,True)
        streamingProducer.resumeProducing()

class ReceivingServer(protocol.Protocol):
    def dataReceived(self, data):
        print("Server received", len(data),"bytes.")

class StreamingClientFactory(protocol.ClientFactory):
    protocol = StreamingClient
    def __init__ (self, reactor):
        self._reactor = reactor

class ReceivingServerFactory(protocol.Factory):
    protocol = ReceivingServer

listener = reactor.listenTCP(port=0,
                           factory=ReceivingServerFactory(),
                           interface='127.0.0.1')
address = listener.getHost()
reactor.connectTCP(host=address.host,
                   port=address.port,
                   factory=StreamingClientFactory(reactor))
reactor.run()

```

`StreamingClient`协议创建一个`StreamingProducer`,然后向其传输注册。如前所述，`registerProducer`的第二个参数是`True`。然而，注册一个生产者并不会自动恢复它，所以我们必须通过调用`resumeProducing`来开始`StreamingProducer`的写循环。注意,`StreamingClient`从不调用它的生产者的`stopProducing`:当反应堆发出断开信号时，transports 代表它们的协议调用这个。

运行此命令会产生如下输出:

```py
Resuming client producer.
Client producer writing 2 bytes.
Server received 2 bytes.
Client producer writing 4 bytes.
Server received 4 bytes.
Client producer writing 8 bytes.
Server received 8 bytes.
...
Client producer writing 524288 bytes.
Pausing client producer.
Server received 65536 bytes.
Server received 65536 bytes.
Server received 65536 bytes.
Server received 65536 bytes.
Resuming client producer.
Client producer writing 1048576 bytes.
Pausing client producer.
...

```

最终，程序将消耗所有可用的内存，从而构成一个成功的流量控制实验。

### 拉动生产者

存在第二个生产者接口:`twisted.internet.interfaces.IPullProducer`。不像`IPushProducer`，它只在它的`resumeProducing`方法被调用时写给它的消费者。这就是`IConsumer.registerProducer`的第二个论点的目的:`IPullProducer` s 要求`streaming`为`False`。不写`IPullProducer` s！大多数传输的行为类似于套接字，并生成可写事件，从而消除了对类似`StreamingProducer`的写循环的需要。当数据必须手动从源中抽出时，编写和测试`LoopingCall`反而更容易。

## 摘要

我们已经看到事件驱动编程如何将程序分成*事件*和它们的*处理程序*。程序发生的任何事情都可以被建模为事件:来自用户的输入、通过套接字接收的数据，甚至是时间的流逝。一个*事件循环*使用一个*多路复用器*来等待任何可能发生的事件，为那些已经发生的事件运行适当的处理程序。操作系统提供底层接口，比如`select`，来复用网络套接字 I/O 事件。使用`select`的事件驱动网络编程在使用*非阻塞*时最为有效，它为`send`和`recv`等操作生成事件，指示程序应该停止运行事件处理程序。

由非阻塞套接字发出的停止事件会导致没有正确抽象的复杂代码。*协议*和*传输*在*原因*和*结果*之间划分程序代码:传输将读取、写入和停止事件翻译成协议可以响应的更高级原因，依次生成新事件。协议和传输之间的这种责任划分允许实现事件处理程序，通过用内存中的假货替换传输，可以很容易地测试这些事件处理程序。稍后，我们将看到协议-传输分离的其他实际好处。

协议、传输和反应器——事件循环的名称——是 Twisted 运行的基础，并贯穿其整体架构。Twisted 的反应器可以对非 I/O 事件做出反应，比如时间的流逝。测试这些并不比测试协议更困难，因为反应堆，像传输一样，在内存中有假货。Twisted 形式化了反应器和其他对象必须通过`zope.interface`实现的接口。通过确定一个对象提供了什么接口，就有可能选择一个适合测试的替代品，它保证是等价的，因为它提供了相同的接口。Twisted 的在线文档使得在 Python 会话中发现接口比检查活动对象更容易。

接口的一个实际应用是 Twisted 对事件驱动的网络编程难以解决的问题的解决方案:流量控制。`IPushProducer`和`IConsumer`定义了一组行为，允许流数据的接收者在不堪重负时暂停数据源。

这个介绍足以解释 Twisted 中事件驱动编程的核心原则。然而，还有更多:在下一章，我们将了解 Twisted 如何通过允许程序处理尚未计算的值来进一步简化事件驱动编程。**