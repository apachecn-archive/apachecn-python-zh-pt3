# 4.在码头扭曲

Docker 常用于微服务架构。这些都是基于通过网络通信的不同组件。Twisted 本身支持多种网络范例，通常非常适合基于 Docker 的架构。

码头工人和一般的集装箱都是新的。工具和关于如何使用工具的共识都在快速发展。我们在这里给出了如何使用 Docker 的基础，因此我们可以在此基础上建立如何使用 Twisted in Docker 的理解。

注意 Docker 是一种基于 Linux 的技术。虽然其他操作系统也有类似的功能，但是 Docker 是建立在利用特定的 Linux 内核功能的基础上的。Docker for Windows 确实能够运行“Windows 容器”，但这超出了本章的范围。

Docker for Mac 和 Docker for Windows 使用运行 Linux 的虚拟机，并与主机操作系统(分别是 OS X 和 Windows)进行了足够的集成，以实现无缝交互。然而，重要的是要记住 Docker 容器总是在 Linux 内核上运行，即使是在 Mac 或 Windows 笔记本电脑上运行。

## intro to docker

因为 Docker 既新又受欢迎，所以有几个不同的东西被称为“Docker”准确理解 Docker *是什么*本身并不简单。我们试图将这里的“Docker”分成不同的概念。注意，这些中的每一个通常被称为“Docker”，以及包括它们的整体。

### 容器

容器是在比传统 UNIX 进程更隔离的情况下运行的进程。

在容器中，唯一可见的进程是那些由容器的根进程启动的进程，在容器中显示为进程 ID `1`。注意，这是可选的:容器可以共享主机的进程 id。使用 Docker 命令行，这是通过参数`--pid host`完成的。

同样，容器也有自己的网络地址。这意味着容器内部的进程可以监听给定的端口，而无需与主机或其他运行的容器协调。同样，可以使用特殊的参数`--net host`运行容器，以便共享主机网络名称空间。

最后，每个容器都有自己的文件系统。例如，这意味着我们可以在不同的容器中安装不同的 Python，而不用担心甚至是冲突的 Python 包。直接共享主机文件系统是很棘手的。

但是，我们可以使用 Docker 的“volume mount”选项。卷装载选项要求在容器内使主机上的目录可访问(“装载”)。该选项的语法是用冒号将目录与主机(左侧)和容器(右侧)中要“装入”的目录分开。

因此，用`--volume /:/from-host`运行 Docker 将使主机的所有文件都可以访问。请注意，它们在容器内部是可访问的，不是在它们通常的位置，而是在`/from-host`目录中。

容器被精确地隔离到它们期望被隔离的程度。这类似于克隆系统调用的标志，指示父进程和子进程之间共享什么:例如，`CLONE_FILES`标志指示共享文件描述符表。

### 容器图像

当*容器*是运行的、孤立的进程集时，*容器映像*允许我们实例化一个容器——它们相当于可执行映像。

在内部，容器映像由*层*组成，每一层代表一个文件系统。容器将看到的最终文件系统(通常称为联合文件系统)是所有层的组合，较高的层覆盖较低的层。上层可以修改、添加甚至“删除”前一层中的文件。虽然下层不会受到影响，但容器内部可见的最终文件系统将受到影响。

这很重要，因为这意味着删除上层文件*并不能*节省空间。例如，如果第一层有一个 tarball，然后将其展开，则 tarball 通常是多余的。上层通常会有`rm/path/to/file.tar.gz`或类似的命令。这在文件名不可见的情况下是好的——但是，在整个容器映像的最终大小中——例如，需要下载多少字节来运行它 tarball 仍将被包括在内。

集装箱图像以其最终位置命名为(或者更准确地说是标签)。通常的命名方案是`[optional host/]` [ `optional user/]name[:optional tag]`。虽然也有例外，但那些永远不会离开构建它们的主机的映像通常会省略`host`和`user`部分。

如果标签关闭，默认为`:latest`。如果主机关闭，默认为`docker.io`。

注意，同一个容器图像可以有多个标签。

容器映像在*注册中心*和*主机*之间移动:它们可以被“推”到注册中心，也可以被“拉”到主机。

### Runc 和 Containerd

为了从一个映像运行一个容器，使用了一个叫做`runc`(“运行容器”)的特殊程序。这个程序负责设置适当的隔离机制:它使用 Linux 内核设施，比如 cgroups 和 namespaces，以便适当地隔离文件系统、进程名称空间和网络地址。

通常，容器用户不会直接与`runc`交互。然而，它被 Docker 堆栈和几乎所有的替代容器堆栈(如 Rocket)在幕后使用。

为了管理正在运行的容器，有必要知道哪些容器正在运行，以及它们的状态如何。出于这个原因，一个名为`containerd`的“守护程序”通过调用`runc`从图像中生成所有容器。

注意，在 Docker 的早期版本中，runc 被嵌入到`containerd`中——所以很多资料仍然将“Docker 守护进程”称为运行容器。

### 客户

与预期相反，命令行`docker run`不运行容器。相反，它与`containerd`守护进程通信，并要求它运行带有`runc`的容器。

默认情况下，它使用 UNIX 域套接字与服务器通信。UNIX 域套接字是基于 UNIX 的操作系统上一种特殊的进程间通信工具。它们的 API 类似于 TCP 套接字，但是它们只用于同一台机器内部的通信，允许内核做一些快捷方式。UNIX 域套接字使用文件路径作为它们的地址，而不是 IP 地址和端口。这允许应用通常的 UNIX 文件权限模型。

默认情况下，`docker`连接的 UNIX 域套接字是`/var/run/docker.sock`。根据 Docker 安装的具体细节，它可能由`docker`组或`root`组访问。Docker 客户端还可以使用 TLS over TCP 连接到服务器，使用 TLS 证书进行相互身份验证。

对于`docker`的所有其他子命令也是如此，比如`build`、`images`等。(注意`docker login`是个例外，但是远程注册中心登录如何工作的解释超出了我们目前的范围。)

因为命令行`docker`主要用于向守护进程发送远程过程调用，所以我们称之为“客户端”

### 登记处

Docker 将图像保存在一个(通常是远程的)*注册表*中。注册表将每个图像存储为一些元数据，加上一组*层*。元数据记录了层的顺序，以及容器图像的一些细节。

请注意，由于这种存储方法，同一层将只存储一次。几个图像共享层的常见情况是具有共同的祖先，这意味着从一个公共基础图像构建的多个图像不需要该图像的自己的副本。

还要注意，默认注册表`docker.io`内置于软件中——如果没有指定注册表，则采用默认注册表——通常称为“DockerHub”

这是单词“Docker”的一种稍微不同的用法，应该再次注意到这是一种可能会引起混淆的术语。

### 建设

构建映像的通常方式是使用`docker build`命令行。这使用了一个被称为`Dockerfile`的配置文件。`Dockerfile`以一条`FROM`线开始。`FROM`标识祖先形象。如果需要一个空图像，`FROM scratch`将使用没有图层的`scratch`图像。然而，这是罕见的。

通常，构建将从一个通用的 Linux 发行版开始，这些发行版都可以从默认的 Docker 注册表 DockerHub 中获得。比如 Debian，Ubuntu，CentOS 都有。

`Dockerfile`中的每一行都是一个“构建阶段”每个构建阶段都会创建一个层，并且层会被缓存。这意味着当修改一个`Dockerfile`时，只有被改变的行(以及它们后面的行)会被执行。

下面的例子就是这样一个`Dockerfile`，它将运行 Twisted web 演示服务器。

```
FROM debian:latest
RUN python3 -m pip install --user Twisted
ENTRYPOINT ["python3", "-m", "twisted", "web"]

```

这并没有展示最佳实践，我们将在查看更复杂的特性时介绍最佳实践，但是它展示了几乎总是出现在`Dockerfile`中的三个重要部分:

*   `FROM`线。在这里，我们要求的是`debian`的`latest`版本。请注意，因为我们没有使用带斜线的名称，所以这来自 DockerHub 上的“库”——一组半官方的基本图像。

*   `RUN`行在正在构建的容器中运行一个命令，通常的效果是以某种方式改变它。在这种情况下，我们将 Twisted 安装成一个`user`安装。

*   `ENTRYPOINT`行设置容器启动时将运行的程序。

### 多阶段构建

上面的解释缺少了一个重要的新功能，是在`docker build`中于 2017 年年中添加的。这些是多阶段构建。当`Dockerfile`中有一个以上的`FROM`行时，就会发生多阶段构建。

当这种情况发生时，构建过程开始构建新的映像，在构建结束时，所有非最终映像都将被丢弃。然而，*当构建运行*时，其他映像可以通过一个`Dockerfile`命令—`COPY`访问。

当使用`COPY --from=<image>`时，它不会从上下文中复制文件，而是从以前的图像中复制。虽然在理论上，多阶段构建可以有任意数量的阶段，但需要两个以上的阶段是非常罕见的。图像的排序使用从 0 开始的编号。大多数“多阶段”构建实际上是“两阶段”构建。第一阶段将构建所有的工件，使用一个充满编译器和构建工具的“厚”映像。第二阶段从第一阶段提取所有的工件，并生成最终的图像进行分发。正因为如此，级间指令通常采用的形式是`COPY --from=0`。

当需要一个复杂的构建环境来生成一些将要部署的产品时，这很有用——最好不要在最终的运行时容器中提供复杂的构建环境:这样可以减少规模、层数和潜在的安全风险。

下面是一个多阶段构建的示例。请注意，在这种情况下，最终输出并不打算直接使用，而是在其他构建中构建。这是一种常见的模式:构建具有通用元素的标准库有几个优点——例如，这可以节省注册表和运行服务器中的空间(如果多个不同的映像在一台服务器上运行，这是常有的事)。另一个好处是当 bug 被修复时，有一个地方可以升级基础包。

```
FROM python:3
RUN mkdir /wheels
RUN pip wheel --wheel-dir /wheels pyrsistent

FROM python:3-slim
COPY --from=0 /wheels /wheels
RUN pip install --no-index --find-links /wheel pyrsistent

```

同样，我们将逐行解释这里发生了什么:

```
FROM python:3

```

`python:3`库是标准“DockerHub 库”库的另一个例子。它包括 Python 3，但也包括足够的工具来构建本机代码轮——至少是简单的，没有进一步的依赖性。

```
RUN mkdir /wheels

```

我们创建目录来存储轮子。请注意，因为这个阶段不会出现在最终输出中，所以我们对创建额外的层并不敏感。事实上，额外的层是好的——它们创造了更多的缓存点。在这种情况下，这没什么意思，但是构建基础通常包括安装更多的构建依赖项。

```
RUN pip wheel --wheel-dir /wheels pyrsistent

```

`pip wheel`子命令在多阶段构建中很有用。它为指定的需求及其所有依赖项构建了一个轮子。如果平台兼容，它将使用 PyPI 为`manylinux`构建的二进制轮——但如果需要，可以用`pip wheel --no-binary :all`关闭这种行为。

```
FROM python:3-slim

```

`python:3-slim`基础类似于 python:3，但是不包括复杂的构建时依赖集。请注意，Python 发行版中的 many :code: `setup.py`会自动检测编译器或依赖项的缺失，并自动关闭本机代码模块的构建。例如，`pyrsistent`有一个 C 优化的持久矢量实现，这是我们想要的。因此，我们不想在这个阶段安装`pyrsistent`。

```
COPY --from=0 /wheels /wheels

```

我们复制刚刚构建的`pyrsistent`轮，以及从第一阶段(阶段 0)到当前阶段的任何依赖关系。第二条`FROM`线表示这是一个多阶段构建——但是这条`COPY`线使多阶段构建变得有用。

```
RUN pip install --no-index --find-links /wheel pyrsistent

```

最后，我们将库安装到本地 Python 环境中。我们小心地为`pip`指定了`--no-index`和`--find-links`选项，这样它将使用第一阶段的轮子，而不是从 PyPI 获得新的发行版。

## Docker 上的 Python

像在任何 UNIX 平台上一样，在 Docker 上部署 Python 应用程序有很多种方法。它们并不完全相同，有些比其他的更好。我们将调查那些效果较好的选项。

### 部署选项

#### 全环境

“全环境”部署意味着有一个专门为应用程序安装的定制 Python 解释器。这个 Python 可以作为 Docker 构建过程的一部分或之前从源代码定制构建，也可以来自元发行版，如`conda`或`nix`。

安装一个定制的 Python 解释器通常是有用的:我们可以在其上定制构建选项，固定解释器版本，甚至在特别极端的情况下，应用定制补丁。然而，这意味着我们承担了使解释器保持最新的任务。

无论我们如何安装这个解释器，它将完全用于我们的应用程序。我们使用`pip install`在其中安装包——或者，如果它来自元发行版(比如`conda`或`nix`),我们也可以从元发行版安装包。这对于 conda 尤其有用，因为有许多与数据科学相关的 Python 包可供安装。

这里有一个例子`Dockerfile`，它构建了一个定制的 Python 解释器，装载了必要的包。

```
FROM buildpack-deps:stretch

ENV PYTHON_VERSION 3.6.4
ENV PREFIX https://www.python.org/ftp/python

ENV LANG C.UTF-8

ENV GPG_KEY 0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D

RUN apt-get update
RUN apt-get install -y --no-install-recommends \
        tcl \
        tk \
        dpkg-dev \
        tcl-dev \
        tk-dev

RUN wget -O python.tar.xz \
    "$PREFIX/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz"
RUN wget -O python.tar.xz.asc \
    "$PREFIX/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc"
RUN export GNUPGHOME="$(mktemp -d)" && \
    gpg --keyserver ha.pool.sks-keyservers.net --recv-keys "$GPG_KEY" && \
    gpg --batch --verify python.tar.xz.asc python.tar.xz
RUN mkdir -p /usr/src/python
RUN tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz

WORKDIR /usr/src/python

RUN gnuArch="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)"
RUN ./configure \
    --build="$gnuArch" \
    --enable-loadable-sqlite-extensions \
    --enable-shared \
        --prefix=/opt/custom-python/
RUN make -j
RUN make install
RUN ldconfig /opt/custom-python/lib
RUN /opt/custom-python/bin/python3 –m pip install twisted

FROM debian:stretch

COPY --from=0 /opt/custom-python /opt/custom-python
RUN apt-get update && \
    apt-get install libffi6 libssl1.1 && \
    ldconfig /opt/custom-python/lib
ENTRYPOINT ["/opt/custom-python/bin/python3", "-m", "twisted", "web"]

```

构建定制的 Python 解释器虽然有用，但并不简单。我们一行一行地检查这个文件:

```
FROM buildpack-deps:stretch

```

对于建筑来说,`buildpack-deps`是一个有用的基础图像。由于我们将使用 Debian“stretch”作为我们的部署版本，在撰写本文时它是最新的稳定 Debian 版本，所以我们得到了 stretch 兼容的 buildpack。

```
ENV PYTHON_VERSION 3.6.4
ENV PREFIX https://www.python.org/ftp/python

```

设置这些可以让我们轻松地修改我们使用的 Python 版本——这对从上游获得新的安全修复和错误修复是必不可少的。我们越容易升级 Python，我们的情况就越好。

```
ENV LANG C.UTF-8

```

将语言明确设置为 UTF-8 是必要的，以避免在 Python 构建过程中出现不明显的错误。虽然在教学上没有启发性，但作为一个放置这些变通办法的地方，这是有用的。将这些细节放在 docker 文件中是确保构建成功的一个方便的地方——无论是在持续集成系统上还是在本地。

```
ENV GPG_KEY 0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D

```

这是 GnuPG 公钥，对应于签署 Python tarball 上传的私钥。Gnu Privacy Guard 是一个使用密码术来实现安全保证的工具。在这种情况下，密钥允许我们知道源代码没有被篡改。这是一个好主意，增加纵深防御，并使用多种方法来验证我们的来源是真实的。这个`Dockerfile`，或者类似的，经常被用在持续集成环境中，在那里它们被重复地和自动地运行。只需一次破坏就能严重危及基础设施。如果源代码没有保证，确保构建失败可以消除代价高昂的生产违规。

将密钥指纹保存在 docker 文件中(可能会签入到源代码控制中)，是在签入的代码中建立信任的一种方式。

```
RUN apt-get update
RUN apt-get install -y --no-install-recommends \
        tcl \
        tk \
        dpkg-dev \
        tcl-dev \
        tk-dev

```

除了 buildpack 之外，我们还需要一些额外的库。我们把它们安装在这里。

```
RUN wget -O python.tar.xz \
    "$PREFIX/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz"

```

接下来，我们下载 Python 源代码 tarball。定义上面的变量可以让我们保持这一行简短明了。此外，即使对于稳定版本来说不是必需的，这个命令行也可以用于像`3.6.1rc2`这样的版本——如果我们想使用这个 docker 文件，只做很小的修改，来测试与候选发布版本的兼容性，那么这个命令行是必需的。

```
RUN wget -O python.tar.xz.asc \
    "$PREFIX/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc"

```

我们下载分离的公钥签名。尽管我们从支持 TLS 的网站下载这两个版本，一个是以`https`为前缀，而不是`http`，检查签名是一个很好的深度防御措施。

```
RUN export GNUPGHOME="$(mktemp -d)" && \
    gpg --keyserver ha.pool.sks-keyservers.net --recv-keys "$GPG_KEY" && \
    gpg --batch --verify python.tar.xz.asc python.tar.xz

```

此命令行验证公钥。注意，这是一个命令的例子，它不*而*改变本地状态。然而，由于任何失败的命令都将停止`docker build`进程，一个关键验证错误将导致构建暂停。

```
RUN mkdir -p /usr/src/python

```

我们为解压后的源代码创建一个目录。注意，由于这是一个多阶段的构建，我们不关心这个目录的最终清理——整个容器都将被清理！

```
RUN tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz

```

我们将 Python tarball 解压到新创建的目录中。

```
WORKDIR /usr/src/python

```

我们将当前工作目录设置为源代码目录。这使得需要从内部运行的后续构建指令更短、更容易理解。

```
RUN gnuArch="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)" && \
  ./configure \
    --build="$gnuArch" \
    --enable-loadable-sqlite-extensions \
    --enable-shared \
        --prefix=/opt/custom-python/

```

我们运行。/configure 脚本，带有自定义前缀。自定义前缀`/opt/custom-python`确保我们将处于一个原始的目录中。我们还提供了一些选项来确保我们的 Python 构建是正确的:

*   使用`dpkg-architecture`计算架构，并显式传递给配置脚本。这比让配置脚本自动检测它更可靠。

*   我们启用`sqlite`模块。由于它是内置的，许多第三方模块将依赖于它而不声明依赖关系，所以确保它是安装的一部分是很重要的。

*   我们启用共享库。在我们的例子中，这不是绝对必要的，但是它允许嵌入 Python 的情况。

```
RUN make -j

```

计算 CPU 的确切数量并不简单。在这个例子中，我们只是以最大并行度运行 make。这就是`-j`标志的作用。注意，一般情况下，建议通过给`-j`一个数字参数，例如`-j` 4，将并行度设置到一个合理的水平。

```
RUN make install

```

此阶段会将具有正确权限的文件复制到安装目录中。

```
RUN ldconfig /opt/custom-python/lib

```

我们将目录添加到我们的库搜索路径中——否则 Python(动态链接的)无法运行。

```
RUN /opt/custom-python/bin/python3 -m pip install twisted

```

我们安装扭曲的。在 Twisted 的许多其他好处中，它包含一个方便的默认 web 服务器，这对演示很有用。

```
FROM debian:stretch

```

对于产品构建，我们从一个合适的最小 Debian 发行版开始——保持它是构建包的匹配版本。

```
COPY --from=0 /opt/custom-python /opt/custom-python

```

我们复制整个环境——包括安装的第三方库:在本例中，是 Twisted 及其依赖项。

```
RUN apt-get update && \
    apt-get install libffi6 libssl1.1 && \
    ldconfig /opt/custom-python/lib

```

我们安装必要的库并在生产映像中运行`ldconfig`。

```
ENTRYPOINT ["/opt/custom-python/bin/python3", "-m", "twisted", "web"]

```

我们设置入口点来运行 Twisted 内置的演示 web 服务器。如果我们构建并运行这个 docker 映像，web 服务器将会运行——如果我们导出端口，我们甚至可以用浏览器检查它。

### Virtualenv(虚拟环境)

完整环境的替代方案是“轻量级”环境，也就是人们所说的虚拟环境。当使用 Python 2.7 时，我们使用`virtualenv`包创建一个虚拟环境。使用`pip`安装`virtualenv`是可能的，但是这有问题:毕竟，如果创建虚拟环境的原因是为了避免改变真实环境，这就失去了好处。一种方法是用我们获得 Python 的方式获得`virtualenv`。另一种方法是使用

```
pip install --user virtualenv

```

这将把它放在*用户*目录下(在 Docker 上，通常在`/root`下)。这通常意味着`virtualenv`不在默认的 shell 路径上——但是因为它在 Python 路径上，

```
python -m virtualenv <directory>

```

仍然可以工作并创建一个虚拟环境。

当使用 Python 3.x 时，这些问题是没有实际意义的:`python -m venv`是为 Python 3.x 创建虚拟环境的最佳方式。请注意，一些文档尚未更新，virtualenv *在 Python 3.x 上运行*——这使得确保所有这些都是最新的变得更加困难。然而，`venv`内置模块的存在极大地简化了虚拟环境的引导。

在虚拟环境中安装代码的好处之一是，我们知道虚拟环境的目录只包含运行它所必需的内容——除了解释器。当我们构建 Docker 映像时，这个特性会派上用场。

把所有这些想法放在一起，我们可能会得出这样一个`Dockerfile`:

```
FROM python:3

```

因为我们要构建一个虚拟环境，所以我们需要已经安装了一个完整的环境。最简单的方法之一是从`python`容器开始。

```
RUN python -m venv /opt/venv-python

```

我们在`/opt/venv-python`中创建一个虚拟环境。

```
RUN /opt/venv-python/bin/pip install Twisted

```

我们在里面安装了扭结。注意，安装 Twisted 意味着安装几个带有 C 扩展的包——这个阶段需要一个 C 编译器。容器映像拥有构建 C 扩展所需的所有工具。

```
FROM python:3-slim

```

`python:3-slim`容器映像没有构建工具。由于这是我们将发布的映像，这意味着我们不会将 C 编译器发布到产品中。

```
COPY --from=0 /opt/venv-python /opt/venv-python

```

我们复制虚拟环境。请注意，虚拟环境中有几个硬编码的路径。这就是为什么我们要确保使用与部署路径相同的路径来创建它。

```
ENTRYPOINT ["/opt/venv-python/bin/python", "-m", "twisted", "web"]

```

入口点与之前的入口点几乎相同。唯一的区别是路径——这次指向的是虚拟环境，而不是完整的环境。

### 最大运动量

最独立的选项是 Pex——Twitter 首创的 Python 可执行格式。Pex 结合了 UNIX、Python 和 Zip 归档的功能，具有包含所有应用程序代码和第三方依赖项的单一文件格式。

Pex 文件应该在文件系统级别被标记为可执行的，例如使用`chmod +x`，并使用调用 Python 解释器的 shebang 行(`!#`)生成。由于 Zip 存档具有独特的属性，即它们是通过它们的最后字节而不是第一个字节来检测和解析的，因此文件的其余部分是一个 Zip 文件。

当 Python 解释器接受一个 Zip 文件，或者一个带有任意内容的 Zip 文件时，它会将其视为 sys.path 附加文件，并且会额外执行存档中的`__main __.py`文件。Pex 文件生成一个定制的`__main__ .py`,它调用入口点或执行 Python 模块，这取决于传递给 Pex builder 的参数。

Pex 可以通过使用`pex`命令行(随`pip install pex`一起安装)、使用`pex`作为 Python 库并使用其创建 API 来构建，也可以通过大多数现代元构建器来构建——Pants、Bazel 和 Buck 都能够生成 Pex 输出。

```
FROM python:3
RUN python -m venv /opt/venv-python

```

我们创造了一个虚拟环境。虽然我们不打算*发布*这个环境，但它将帮助我们构建 Pex 文件。

```
RUN /opt/venv-python/bin/pip install pex

```

我们安装 pex 实用程序。

```
RUN mkdir /opt/wheels /opt/pex

```

我们创建两个目录来包含不同种类的产品。

```
RUN /opt/venv-python/bin/pip wheel --wheel-dir /opt/wheels Twisted

```

我们用`pip`来制造轮子。这意味着我们将使用`pip`依赖解析算法。虽然客观上并不比`pex`算法更好，但它是其他任何地方都使用的算法。这意味着如果软件包在`pip`依赖关系解析过程中遇到问题，它们将添加正确安装所需的任何提示。不常用的`pex`就没有这种保证。

```
RUN /opt/venv-python/bin/pex --find-links /opt/wheels --no-index \
                             Twisted -m twisted -o /opt/pex/twisted.pex

```

我们构建 Pex 文件。注意，我们告诉`pex`忽略 PyPI 索引，只从一个特定的目录中收集包——在这个目录中`pip`放置了它构建的所有轮子。我们配置 Pex 文件的行为就像我们用`-m twisted`运行 Python 一样，我们把输出放在`/opt/pex`中。虽然后缀不是绝对必要的，但在检查 Docker 容器图像时，它非常有用，有助于理解事物是如何运行的。

```
FROM python:3-slim

```

同样，我们避免使用第二阶段的`slim`映像将构建工具交付给生产。

```
COPY --from=0 /opt/pex /opt/pex

```

我们复制目录——这一次，它只有一个文件。还要注意，这一次，文件是可重定位的:可以(尽管我们在这里不这样做)复制到不同的路径。

```
ENTRYPOINT ["/opt/pex/twisted.pex", "web"]

```

在前面的例子中驻留在`ENTRYPOINT`(我们想要运行`python -m twisted`)中的一些逻辑现在被构建到 Pex 文件中。我们的`ENTRYPOINT`现在更短了。

### 构建选项

不管 Python 是以什么方式*运行*的，Docker 容器是以什么方式*构建的*也有很多选择。

### 一个大包

一种方法是完全避免多阶段构建，使用构建环境所需的任何工具构建一个容器。这通常意味着容器很大，有很多层。

虽然这种方法简单、直接且易于调试，但它也有缺点。容器尺寸很容易成为生产中的一个问题。类似地，层数减慢了容器的部署。最后，将大量的包放在一个暴露于潜在的恶意用户输入的容器中会导致更多的攻击媒介。

### 阶段之间的复制轮

另一种方法是在构建阶段构建所有轮子，包括任何二进制轮子，然后将它们复制到生产阶段。在这种情况下，生产阶段仍然需要足够的工具来创建一个虚拟环境并在其中安装这些轮子——尽管由于`venv`是 Python 3 中的一个 Python 内置模块，这通常不再是一个难题。

还有另外两个问题:轮子在安装后仍然存在，因为在切换层后不可能真正删除一个文件；并且它经常创建额外的层(尽管通过巧妙的重新排序和反斜杠继续的行，这有时是可以避免的)。

### 在阶段之间复制环境

另一个部署选项是将环境(可以是完整的或虚拟的)从构建阶段复制到生产阶段。这种方法的优点是快速、简单，缺点是没有兼容性检查、依赖性检查或位置检查。尽管如此，如果对生成的容器进行了适当的测试，通常会发现基本的不兼容问题。

### 在阶段之间复制 Pex 可执行文件

最后，如果 Pex 可执行文件是在构建阶段生成的，那么复制它是很简单的。当然，Pex 文件会在运行时寻找依赖关系。然而，它会做一个可靠的检查，所以即使启动容器也足以测试它。

它也是可重定位的，所以它从哪里拷贝或者拷贝到哪里都没有关系。Pex 和 Docker 通常是很好的组合。然而，Pex 的固有限制(例如，预构建的二进制轮子支持差或 PyPy 支持差)有时使它无法成功。

### Dockerpy 自动化

一个名为`dockerpy`的包允许用 Python 实现 Docker 步骤的自动化。虽然通常在生产中运行容器，我们将使用编排框架，这通常对构建和测试容器有用。`dockerpy`库允许我们仔细微调发送给 Docker 守护进程的上下文——使用`tarfile` Python 模块，可以精确地制作所需的上下文。

## 在码头上扭转

### 入口点和 PID 1

Docker 的`ENTRYPOINT` Dockerfile 指令中的进程在容器内部将具有进程 ID 1。进程 ID 1 在 Linux 上有特殊的责任。当一个进程的父进程在它死亡之前死亡时，PID 1“采用”它——成为它的父进程。这意味着当子进程终止时，PID 1 需要“收获它”——等待它的退出状态，以便从进程表中清除进程条目。

这个责任有点诡异，很多节目都不是为它设置的。当运行一个不接收领养儿童的程序时，进程表将会填满。在最好的情况下，这将使容器崩溃。在最坏的情况下，当没有仔细设置进程限制时，这可能会使运行容器的整个机器(虚拟的或物理的)崩溃。

幸运的是，*任何*扭曲的程序都设置为 PID 1。这是因为 Twisted 的流程基础设施会自动收获预期的和意外的孩子。

这意味着当构建一个容器时，如果我们用它来运行 WSGI 应用程序，或者 Klein 应用程序，或者 Buildbot master，让它作为入口点是很好的。

事实上，由于这个原因，如果有任何自定义的启动代码要做，可以考虑将其实现为 tap 插件。这样，Twisted 还是可以作为切入点的。

### 自定义插件

当编写一个在 Docker 中运行的 Twisted 应用程序时，我们几乎总是希望将它作为一个定制的`tap`插件来交付。这使得`ENTRYPOINT`简单

```
["/path/to/python", "-m", "twisted", "custom_plugin"]

```

这意味着插件可以获得传递给`docker run`命令的任何参数——因为这些参数被直接添加到`ENTRYPOINT`参数中。这也意味着插件可以直接读取通过`--env`传递给`docker run`的任何环境变量。

在插件中，`makeService`函数是返回正在运行的服务的函数。请注意，插件可以在该函数中进行任何它想要的初始化——事件循环此时还没有运行。

### 殖民地

有时，有必要在 Docker 容器中运行多个进程。也许是一些辅助进程来清理文件，或者是一个多进程设置来使用多个 CPU。在这种情况下，一个进程管理者是有用的——运行几个进程，监视它们，并在必要时重新启动它们。

NColony 是一个基于 Twisted 的流程主管。它是围绕`twisted.runner.procmon`的一个小垫片，允许几个灵活的配置选项。NColony 将配置作为描述进程的 JSON 格式文件的目录。

当然，也可以通过打开一个文件并将 JSON 写入其中来直接创建这些文件。然而，NColony 还附带了一个命令行实用程序—`python -m ncolony ctl`—来创建这样的文件，以及一个 Python 库—`ncolony.ctllib`。

目录模型的一个优点是，这意味着它可以与 Docker 容器的层模型很好地交互。一个本地基础容器可以有一个`["python", "-m", "twisted", "ncolony", ...]`的`ENTRYPOINT`，甚至在配置目录中有几个基础进程——通常是`/var/run/ncolony/config/`。然后，特定的 containerd 可以在这个目录中转储它们自己的文件，这些文件是在容器的构建阶段使用例如`python -m ncolony ctl`创建的。最终的容器将同时运行副进程和主进程。

这里有一个例子，它将本章讨论的大部分内容具体化了:

```
FROM python:3
RUN python3 -m venv /application/env
RUN /application/env/bin/pip install ncolony
RUN mkdir /application/config /application/messages
RUN /application/env/bin/python -m ncolony \
    --config /application/config \
    --messages /application/messages \
    ctl \
    --cmd /application/env/bin/python \
    --arg=-m \
    --arg=twisted \
    --arg=web

FROM python:3-slim
COPY --from=0 /application/ /application/
ENTRYPOINT ["/application/env/bin/python", \
            "-m", \
            "twisted", \
            "ncolony", \
            "--config", "/application/config", \
            "--messages", "/application/messages"]

```

我们一行一行地检查，这里有很多东西。

```
FROM python:3

```

获得我们的 Python 环境的一种方法是使用官方的 Docker(“库”)映像。这是基于 Debian 发行版的，其中有 Python——以及构建 Python 和 Python 扩展模块所需的所有工具。

```
RUN python3 -m venv /application/env

```

我们在`/application/env`中创建一个虚拟环境。如前所述，Python 3 使虚拟环境成为一个内置的概念，我们充分利用了它。

```
RUN /application/env/bin/pip install ncolony

```

为了更好的可重复构建，最好是复制一个需求文件——最好是一个也有散列的文件——`pip install`。然而，当我们直接使用一个包名时，更容易看到发生了什么。

```
RUN mkdir /application/config /application/messages

```

NColony 需要两个目录才能正常工作:一个用于配置，一个用于消息。我们在`/application`下创建它们。配置是需要运行的一组进程及其参数。消息是瞬时请求——通常是重启一个或多个进程的请求。

```
RUN /application/env/bin/python -m ncolony \

```

我们从安装在`/application/env`虚拟环境中的 NColony 运行子命令。

```
--config /application/config \
--messages /application/messages \

```

我们传递 NColony 的参数。虽然在这种情况下没有使用 messages 目录，但是最好将它们都传递给所有命令。

```
ctl \

```

Control ( `ctl`)是控制配置的 NColony 子命令。

```
--cmd /application/env/bin/python \

```

我们运行与我们运行的 Python 相同的 Python。注意，一般来说，这对于 NColony 来说是不必要的。然而，为不同的用途编写使用完全不同的解释器的代码会令人困惑。

```
--arg=-m \
--arg=twisted \

```

NColony 正在监控的进程不一定是一个扭曲的进程，但在我们的例子中，它将是一个扭曲的进程——事实上，是另一个`tap`插件。

```
--arg=web

```

当没有给定参数时，web `tap`插件显示一个演示 web 应用程序。这对于快速演示和检查来说非常有用——就像这个例子一样。

```
FROM python:3-slim

```

第二行`FROM`开始生产 Docker 图像。注意——当构建完成时，到目前为止构建的所有东西都将被*丢弃*。早期步骤存在的唯一原因是从那个短暂的阶段复制。这个源映像是一个最小的 Debian，加上一个已安装的 Python 3。

```
COPY --from=0 /application/ /application/

```

我们复制整个应用程序目录。因为这个目录既有虚拟环境又有 NColony 配置，所以我们不需要其他东西。这一行的简单性解释了我们为设置这个目录所做的所有细致工作的价值。

```
ENTRYPOINT ["/application/env/bin/python", \ "-m", \
            "twisted", \ "ncolony", \
            "--config", "/application/config", \
            "--messages", "/application/messages"]

```

最后，我们配置入口点。由于 NColony 本身是一个 tap 插件，我们再次运行的命令是`python -m twisted <plugin>`。

在这个例子中，我们可以直接运行 web 服务器作为入口点。然而，一个实际上需要几个进程的更现实的例子会掩盖让 NColony 在 Docker 中运行的基本机制。

## 摘要

Docker、Python 和 Twisted 是互补的技术。具有多阶段构建和注册的 Docker 为 Python 提供了一种标准化的方式来指定构建过程和打包。Twisted 及其进程管理原语为 Docker 提供了一个有用的 PID 1，它可以独立完成有用的工作——例如 web 服务器——或者是一个强大的基础层 NColony 非常适合 Docker 层模型。

Docker 是构建、打包和运行 Twisted 应用程序的实用方法，而 Twisted 是在 Docker 内部运行的有用工具。