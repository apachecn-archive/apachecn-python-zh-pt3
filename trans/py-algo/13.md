附录 B

![image](images/frontdot.jpg)

问题和算法列表

如果你有船体问题，我为你感到难过，孩子；我有 99 个问题，但违规不是一个。

—匿名 [<sup>1</sup>](#Fn1)

本附录没有列出书中提到的每个问题和算法，因为讨论一些算法只是为了说明一个原理，而一些问题只是作为某些算法的例子。然而，最重要的问题和算法在这里用一些对正文的参考被勾画出来。如果你不能通过查阅这个附录找到你要找的东西，那就看看索引。

在本附录的大部分描述中， *n* 指的是问题大小(比如一个序列中元素的个数)。对于图的特殊情况，虽然， *n* 是指节点数， *m* 是指边数。

问题

**小集团和独立集团。**一个*集团* 是一个图，其中每对节点之间都有一条边。这里感兴趣的主要问题是在一个更大的图中寻找一个团(即把一个团识别为一个子图)。图中的独立集是指没有一对节点通过边相连的节点集。换句话说，找一个独立集相当于取边集的补集，找一个小团体。寻找一个*k*-团(由 *k* 个节点组成的团)或者寻找一个图中最大的团(最大团问题)是 NP-hard。(更多信息，参见第 11 章。)

**最亲密的一对。**给定欧几里得平面上的一组，找出彼此最接近的两个点。这可以使用分治策略在线性时间内解决(见第 6 章[)。](06.html)

**压缩和最优决策树。**一棵 霍夫曼树是一棵的树，它的叶子有权重(频率)，它们的权重乘以深度的和尽可能小。这使得这种树对于构造压缩码是有用的，并且当结果的概率分布已知时，这种树可以作为决策树。霍夫曼树可以使用霍夫曼算法来构建，在[第 7 章](07.html) ( [清单 7-1](07.html#list1) )中有描述。

**连通和强连通分量。无向图是连通的，如果有一条路径从每个节点到其他节点。有向图是连通的，如果它的底层无向图是连通的。连通分量是连通的最大子图。举例来说，可以使用诸如 DFS ( [清单 5-5](05.html#list5) )或 BFS ( [清单 5-9](05.html#list9) )之类的遍历算法来找到连接的组件。如果在一个有向图中有一条从每个节点到其他节点的(有向)路径，称之为*强*连通。强连通分量(SCC) 是强连通的极大子图。可以使用 Kosaraju 的算法找到 SCC([清单 5-10](05.html#list10) )。**

**凸包。**一个凸包是欧几里得平面中包含一组点的最小凸区域。使用分治策略可以在对数线性时间内找到凸包(见[第 6 章](06.html))。

**寻找最小值/最大值/中值。**寻找一个序列的最小值和最大值可以通过简单的扫描在线性时间内找到。给定线性时间准备，可以使用二进制堆在恒定时间内重复查找和提取最大值或最小值。使用选择或随机选择，也可以在线性(或预期线性)时间内找到序列的第 *k* 个最小元素(k*k*=*n*/2 的中值)。(更多信息，参见第 6 章[。)](06.html)

**流与切问题** **。**在边上有流量容量的网络中，可以推送多少个单位的流量？那就是最大流量问题。一个等价的问题是找到最能限制流量的边容量集；这就是 min-cut 问题。这些问题有几种版本。例如，您可以将成本添加到边中，并找到最大流量中最便宜的流量。你可以在每条边上加一个下界，寻找一个可行的流。您甚至可以在每个节点中添加单独的供应和需求。这些问题将在第 10 章中详细讨论。

**图形着色。** 尝试给图的节点上色，这样就不会有邻居共享一种颜色。现在尝试用给定数量的颜色来做这件事，或者甚至找到最低的数量(图中的*色数*)。一般来说这是一个 NP 难问题。然而，如果要求您查看一个图是否是二色的(或二分的)，这个问题可以使用简单遍历在线性时间内解决。寻找团覆盖的问题等价于寻找独立集覆盖，这是一个与图着色相同的问题。(参见[第 11 章](11.html)了解更多关于图形着色的信息。)

磕磕绊绊的问题。确定给定的算法是否会随着给定的输入而终止。问题在一般情况下是不可判定的(即不可解的)(见[第十一章](11.html))。

汉密尔顿循环/路径和 TSP …以及欧拉旅行。几个 路径和子图问题都可以高效解决。但是，如果您想对每个节点只访问一次，那就麻烦了。任何涉及这个约束的问题都是 NP 难的，包括寻找一个哈密尔顿圈(访问每个节点一次并返回)，一个哈密尔顿路径(访问每个节点一次，不返回)，或者一个完整图的最短旅行(旅行推销员/销售代表问题)。无论是有向还是无向的情况，问题都是 NP 难的(见[第十一章](11.html))。然而，访问每条*边*恰好一次的相关问题——找到所谓的欧拉之旅——可以在多项式时间内解决(参见[第 5 章](05.html))。TSP 问题是 NP 难的，即使对于特殊情况，例如使用平面中的欧几里德距离，但是对于这种情况，以及对于任何其他度量距离，它可以有效地近似到 1.5 倍以内。然而，一般来说，近似 TSP 问题是 NP 难的。(更多信息见第 11 章。)

**背包问题和整数规划。**背包问题涉及在一定的约束条件下，选择一组物品中有价值的子集。在(有界)分数的情况下，你有一定量的一些物质，每种物质都有一个单位值(单位重量的值)。你也有一个可以承载一定最大重量的背包。(贪婪的)解决方案是尽可能多地获取每种物质，从单位价值最高的物质开始。对于整数背包问题，你只能拿整个项目，不允许分数。每样东西都有重量和价值。对于有界情况(也称为 0-1 背包)，每种类型的对象数量有限。(另一种观点是，你有一套固定的物品，你要么拿，要么不拿。)在无界的情况下，您可以从一组对象类型中的每一个中获取您想要的数量(当然，仍然考虑您的承载能力)。称为子集和问题的特殊情况涉及选择一组数的子集，使得该子集具有给定的和。这些问题都是 NP 难的(见[第 11 章](11.html)，但是承认基于动态规划的伪多项式解(见[第 8 章](08.html))。如前所述，分数背包问题甚至可以使用贪婪策略在多项式时间内解决(参见第 7 章)。在某种程度上，整数规划是背包问题的推广(因此显然是 NP 难的)。它是简单的线性规划，其中变量被约束为整数。

**最长递增子序列。**寻找给定序列中元素按升序排列的最长子序列。这可以使用动态规划在对数线性时间内解决(见第 8 章的[)。](08.html)

**匹配。**有许多匹配问题，都涉及到将一些对象链接到其他对象。本书讨论的问题是二部匹配和最小代价二部匹配([第十章](10.html))和稳定婚姻问题([第七章](07.html))。二分匹配(或最大二分匹配)涉及在二分图中寻找边的最大子集，使得子集中没有两条边共享一个节点。最小成本版本做同样的事情，但是最小化这个子集上的边成本的总和。稳定的婚姻问题有点不一样；在那里，所有的男人和女人都有对异性成员的偏好排名。一套稳定的婚姻的特点是，你找不到一对愿意拥有对方而不是现在的另一半。

**最小生成树。**生成树是一个子图，它的边在原图的所有节点上形成一棵树。最小生成树是最小化边成本总和的树。例如，可以使用克鲁斯卡尔算法([列表 7-4](07.html#list4) )或普里姆算法([列表 7-5](07.html#list5) )找到最小生成树。因为边的数量是固定的，所以可以通过简单地否定边权重来找到最大生成树。

**分割和装箱。**划分 涉及将一组数分成两个和相等的集合，而装箱问题涉及将一组数打包成一组“箱”，使得每个箱中的和低于某个限制，并且箱的数量尽可能少。这两个问题都是 NP 难的。(参见[第十一章](11.html)。)

**SAT，巡回赛-SAT，*****k*****-CNF-SAT。**这些都是满意度问题(SAT)的变种，它要求你确定一个给定的逻辑(布尔)公式是否为真，如果你被允许将变量设置为你想要的任何真值。circuit-SAT 问题简单地使用逻辑电路而不是公式， *k* -CNF-SAT 涉及合取范式的公式，其中每个子句由 *k* 文字组成。对于 *k* = 2，后者可以在多项式时间内求解。其他的问题，以及 *k* -CNF-SAT 对于*k*T23】2，都是 NP 完全的。(参见[第十一章](11.html)。)

**搜索。**这个是一个非常普遍又极其重要的问题。您有一个键，并希望找到一个相关的值。例如，这就是 Python 等动态语言中变量的工作方式。这也是如今你在网上几乎能找到任何东西的方式。两个重要的解决方案是哈希表(见第 2 章的[和二分搜索法或搜索树(见第 6 章](02.html)的[)。给定数据集中对象的概率分布，可使用动态规划构建最佳搜索树(见第 8 章](06.html))。

**序列比较。**你可能想要比较两个序列，以了解它们有多相似(或不相似)。一种方法是找到两者共同的最长子序列(最长公共子序列)，或者找到从一个序列到另一个序列的基本编辑操作的最小数量(所谓的编辑距离，或 Levenshtein 距离)。这两个问题或多或少是等价的；更多信息参见[第 8 章](08.html)。

**序列修改。**在链表中间插入一个元素代价很小(常数时间)，但是寻找给定位置代价很大(线性时间)；对于数组，情况正好相反(常量查找、线性插入，因为所有后面的元素都必须移位)。不过，对于这两种结构来说，附加都可以很便宜地完成(见[第二章](02.html)中`list`的“黑盒”边栏)。

**集合和顶点覆盖。**一个一个顶点覆盖是覆盖(即相邻)图的所有边的顶点的集合。集合覆盖是这一思想的推广，其中节点被子集代替，并且您想要覆盖整个集合。问题在于限制或最小化节点/子集的数量。这两个问题都是 NP 难的(见[第 11 章](11.html))。

**最短路径。**这个问题涉及到寻找从一个节点到另一个节点，从一个节点到所有其他节点(反之亦然)，或者从所有节点到所有其他节点的最短路径。一对一、一对一和一对一的情况以同样的方式解决，通常对未加权图使用 BFS，对 DAG 使用 DAG 最短路径，对非负边权重使用 Dijkstra 算法，在一般情况下使用 Bellman–Ford。为了在实践中加快速度(虽然不影响最坏情况下的运行时间)，还可以使用双向 Dijkstra，或 A*算法。对于所有对最短路径问题，选择的算法可能是 Floyd-Warshall 或(对于稀疏图)Johnson 算法。如果边是非负的，Johnson 算法(渐近地)等价于从每个节点运行 Dijkstra 算法(可能更有效)。(关于最短路径算法的更多信息，参见[第 5 章](05.html)和[第 9 章](09.html)。)注意*最长*路问题(对于一般图)可以用来求哈密尔顿路，也就是说它是 NP 难的。这实际上意味着最短路径问题在一般情况下也是 NP 难的。然而，如果我们不允许图中有负循环，我们的多项式算法将会起作用。

**排序和元素唯一性。**排序 是一个重要的操作，也是其他几个算法必不可少的子程序。在 Python 中，通常使用`list.sort`方法或`sorted`函数进行排序，这两种方法都使用 timsort 算法的高效实现。其他算法包括插入排序、选择排序和 gnome 排序(所有这些都有二次运行时间)，以及堆排序、合并排序和快速排序(它们是对数线性的，尽管这仅适用于快速排序的一般情况)。关于二次排序算法的信息，见第 5 章[；关于对数线性(分治)算法，见第 6 章](05.html)[。判定一组实数是否包含重复项不能(在最坏的情况下)用比对数线性更好的运行时间来解决。通过还原，排序也不能。](06.html)

**拓扑排序。** 对一个 DAG 的节点进行排序，使所有的边都指向同一个方向。如果边表示依赖性，则拓扑排序表示尊重依赖性的排序。这个问题可以通过引用计数的形式来解决(参见[第 4 章](04.html))或者使用 DFS(参见[第 5 章](05.html))。

**遍历。**这里的问题是访问一些连通结构中的所有对象，通常表示为图或树中的节点。这个想法可以是要么访问每个节点，要么只访问那些需要解决某个问题的节点。忽略图或树的一部分的后一种策略被称为*修剪* ，并且被用于(例如)搜索树和分支定界策略。关于遍历的更多内容，请参见第 5 章。

算法和数据结构

**2-3 棵树。**平衡的树形结构，允许在最坏情况下θ(LG*n*时间内进行插入、删除和搜索。内部节点可以有两到三个子节点，在插入过程中，根据需要通过拆分节点来平衡树。(参见[第六章](06.html)。)

**A*。**启发式引导的单源最短路径算法。适合大搜索空间。不是选择具有最低距离估计值的节点(如 Dijkstra 的),而是使用具有最低启发值(距离估计值和剩余距离猜测值之和)的节点。最坏情况下的运行时间与 Dijkstra 算法相同。(参见[清单 9-10](09.html#list10) 。)

**AA 树。** 2-3-trees 使用节点旋转模拟了一个节点级别编号的二叉树。插入、删除和搜索的最坏情况运行时间为θ(LG*n*)。(参见[清单 6-6](06.html#list6) 。)

贝尔曼-福特。加权图中从一个节点到所有其他节点的最短路径。沿着每条边寻找捷径 *n* 次。没有负周期，在*n*–1 次迭代后保证正确答案。如果最后一轮有所改善，则检测到负循环，算法放弃。运行时间θ(*nm*)。(参见[清单 9-2](09.html#list2) 。)

**双向 Dijkstra。** Dijkstra 的算法从开始和结束节点同时运行，交替迭代到两个算法中的每一个。当两者在中间相遇时，找到最短的路径(尽管在这一点上必须小心)。最坏情况下的运行时间就像 Dijkstra 算法一样。(参见[列表 9-8](09.html#list8) 和[列表 9-9](09.html#list9) 。)

**二分搜索法树。**一个二叉树结构，其中每个节点都有一个键(通常还有一个关联值)。后代键由节点键划分:较小的键放在左边的子树中，较大的键放在右边。平均来说，任何节点的深度都是对数的，给出了期望的插入和搜索时间θ(LG*n*)。但是，如果没有额外的平衡(比如在 AA 树中)，树会变得不平衡，给出线性运行时间。(参见[清单 6-2](06.html#list2) 。)

**平分，二分搜索法。**一种搜索程序，其工作方式类似于搜索树，通过重复将排序序列中感兴趣的区间减半。通过检查中间元素并决定所寻找的值必须位于左侧还是右侧来执行减半。运行时间θ(LG*n*)。一个非常有效的实现可以在`bisect`模块中找到。(参见[第六章](06.html)。)

**分支和捆绑。**一种通用算法设计方法。通过构建和评估部分解决方案，以深度优先或最佳优先的顺序搜索解决方案空间。为最佳值保留保守估计，而为部分解决方案计算乐观估计。如果乐观估计比保守估计差，则不扩展部分解，并且算法回溯。常用于解决 NP 难问题。(参见清单 11-2 中的[获得 0-1 背包问题的分支定界解决方案。)](11.html#list2)

广度优先搜索(BFS)。 逐层遍历一个图(可能是一棵树)，从而也识别(未加权)最短路径。通过使用 FIFO 队列跟踪发现的节点来实现。运行时间θ(*n*+*m*)。(参见[清单 5-9](05.html#list9) 。)

**桶排序。**对给定区间内均匀分布的数值进行排序，方法是将区间分成 *n 个*大小相等的桶，并将值放入其中。预期的存储桶大小是恒定的，因此可以使用(例如)插入排序对它们进行排序。总运行时间θ(*n*)。(参见[第 4 章](04.html)。)

**Busacker–go Wen。**通过使用福特-富尔克森方法中最便宜的扩充路径，找到网络中最便宜的最大流(或给定流值的最便宜的流)。这些路径是使用贝尔曼-福特或(经过一些权重调整)Dijkstra 算法找到的。运行时间通常取决于最大流量值，伪多项式也是如此。对于最大流量 *k* ，运行时间为 *O* ( *km* lg *n* )。(参见[清单 10-5](10.html#list5) 。)

**克里斯托菲德斯算法。**度量 TSP 问题的近似算法(近似比界限为 1.5)。找到一个最小生成树，然后在树的奇数度节点中找到一个最小匹配 [<sup>2</sup>](#Fn2) ，根据需要进行短路以对图进行有效浏览。(参见[第十一章](11.html)。)

**计数排序。**在θ(*n*)时间内对取值范围小(最多有θ(*n*个连续值)的整数进行排序。其工作原理是对出现次数进行计数，并使用累积计数将数字直接放入结果中，并在进行过程中更新计数。(参见[第 4 章](04.html)。)

**DAG 最短路径。**寻找从一个节点到 DAG 中所有其他节点的最短路径。工作原理是找到节点的拓扑排序，然后从左到右放松每个节点的所有出边(或者所有入边)。也可以(因为缺少循环)用来寻找*最长的*路径。运行时间θ(*n*+*m*)。(参见[清单 8-4](08.html#list4) 。)

深度优先搜索。 通过深入然后回溯来遍历图(可能是树)。通过使用 LIFO 队列跟踪发现的节点来实现。通过跟踪发现时间和结束时间，DFS 还可以用作其他算法(如拓扑排序或 Kosaraju 算法)中的子例程。运行时间θ(*n*+*m*)。(参见[清单 5-4](05.html#list4) 、 [5-5](05.html#list5) 和 [5-6](05.html#list6) )。)

**迪杰斯特拉的算法。**在赋权图中找出从一个节点到所有其他节点的最短路径，只要没有负的边权重。遍历图，使用优先级队列(堆)重复选择下一个节点。优先级是节点的当前距离估计。每当从被访问的节点发现快捷方式时，这些估计被更新。运行时间是θ((*m*+*n*)LG*n*)，如果图是连通的，简单来说就是θ(*m*LG*n*)。

**双头队列。** FIFO 使用链表(或数组链表)实现的队列，这样在两端插入和提取对象可以在恒定的时间内完成。一个有效的实现可以在`collections.deque`类中找到。(参见[第 5 章](05.html)中关于该主题的“黑盒”侧栏。)

**动态数组，向量。**在数组中有额外的容量，所以追加是有效的。通过将内容重新定位到一个更大的数组，以常数因子增长它，当它填满时，追加可以在平均(摊销)时间内保持不变。(参见[第二章](02.html)。)

埃德蒙兹-卡普。Floyd–war shall 方法的具体实例，其中使用 BFS 执行遍历。在θ(*nm*T5】2 时间内求最小费用流。(参见[清单 10-4](10.html#list4) 。)

弗洛伊德-沃肖尔。寻找从每个节点到所有其他节点的最短路径。在迭代 *k* 中，只有第一个 *k* 节点(按某种顺序)被允许作为路径上的中间节点。从*k*–1 扩展包括检查通过第一个*k*–1 节点往返于 *k* 的最短路径是否比直接通过这些节点更短。(即，对于每个最短路径，节点 *k* 要么被使用，要么不被使用。)运行时间为θ(*n*T17】3)。(参见[清单 9-6](09.html#list6) 。)

福特-富尔克森。一个解决最大流问题的通用方法。该方法包括重复遍历该图以找到所谓的增加路径，即流量可以增加(增加)的路径。如果有额外的容量，可以沿着边缘增加流量，或者如果沿着边缘有流量，可以沿着边缘向后*增加*(即取消)。因此，遍历可以沿着有向边向前和向后移动，这取决于穿过它们的流。运行时间取决于使用的遍历策略。(参见[清单 10-4](10.html#list4) 。)

**盖尔-沙普利。**发现一组稳定的婚姻给出了一组男性和女性的偏好排名。任何没有订婚的男人都会向他们还没有求婚的最喜欢的女人求婚。每个女人都会在目前的追求者中选择自己喜欢的(可能会和未婚夫在一起)。可以用二次运行时间来实现。(参见第七章中的侧栏“热切的追求者和稳定的婚姻”。)

**侏儒排序。**一个简单的二次运行时间排序算法。可能不是你在实践中会用到的算法。(参见[清单 3-1](03.html#list1) 。)

**哈希，散列表。**查找 向上一个键得到相应的值，就像在一个搜索树中一样。条目存储在一个数组中，它们的位置通过计算关键字的(伪随机的，类似于)*哈希值*找到。给定一个好的散列函数和数组中足够的空间，插入、删除和查找的预期运行时间是θ(1)。(参见[第二章](02.html)。)

**成堆，堆积如山。**堆是高效的优先级队列。使用线性时间预处理，min- (max-)堆将让您在常数时间内找到最小(最大)的元素，并在对数时间内提取或替换它。添加一个元素也可以在对数时间内完成。从概念上讲，堆是一个完整的二叉树，其中每个节点都比其子节点小(大)。修改时，可以用θ(LG*n*运算修复该属性。实际上，堆通常使用数组实现(节点编码为数组条目)。一个非常有效的实现可以在`heapq`模块中找到。Heapsort 类似于 selection sort，只是未排序的区域是一个堆，因此查找最大元素 *n* 次的总运行时间为θ(*n*LG*n*)。(参见第 6 章中[关于堆、`heapq`和堆排序的“黑盒”侧栏。)](06.html)

**霍夫曼算法。**构建霍夫曼树，例如，可用于构建最佳前缀码。最初，每个元素(例如，字母表中的字符)被制成单节点树，权重等于其频率。在每次迭代中，选取两个最轻的树，将它们与一个新的根合并，并赋予新树一个等于原来两个树权重之和的权重。这可以在对数线性时间内完成(或者，实际上，如果频率被预先分类，则可以在线性时间内完成)。(参见[清单 7-1](07.html#list1) 。)

**插入排序。**一个简单的二次运行时间排序算法。它的工作方式是在数组的初始排序段中重复插入下一个未排序的元素。对于小数据集，它实际上比更高级(和最优)的算法更可取，如合并排序或快速排序。(但是，在 Python 中，如果可能的话，应该使用`list.sort`或`sorted`。)(见[清单 4-3](04.html#list3) 。)

**插值搜索。**类似于普通的二分搜索法，但是使用区间端点之间的线性插值来猜测正确的位置，而不是简单地查看中间元素。最坏情况下的运行时间仍然是θ(LG*n*，但是对于均匀分布的数据，平均情况下的运行时间是 *O* (lg lg *n* )。(在第 6 章的[部分的“如果你好奇……”中提到。)](06.html)

**迭代深化 DFS。**DFS 的重复运行，其中每一次运行都有一个它可以遍历的距离的限制。对于具有一些扇出的结构，运行时间将与 DFS 或 BFS 相同(即θ(*n*+*m*))。关键是它具有 BFS 的优点(它找到最短的路径，保守地探索大的状态空间)，具有 DFS 较小的内存占用。(参见[清单 5-8](05.html#list8) 。)

**约翰逊算法。**寻找从每个节点到所有其他节点的最短路径。基本上从每个节点运行 Dijkstra 的。然而，它使用了一个技巧，以便它也可以处理负边权重:它首先从新的开始节点运行 Bellman-Ford(向所有现有节点添加边)，然后使用结果距离来修改图的边权重。修改后的权重都是非负的，但是被设置为使得原始图中的最短路径也将是修改后的图中的最短路径。运行时间θ(*Mn*LG*n*)。(参见[清单 9-4](09.html#list4) 。)

**Kosaraju 的算法。**使用 DFS 找到强连接的组件。首先，节点按其完成时间排序。然后反转边，运行另一个 DFS，使用第一个排序选择开始节点。运行时间θ(*n*+*m*)。(参见[清单 5-11](05.html#list11) 。)

**克鲁斯卡尔的算法。**通过重复添加不产生循环的最小剩余边来寻找最小生成树。这种循环检查可以(用一些小技巧)非常有效地执行，所以运行时间主要由边的排序决定。总而言之，运行时间为θ(*m*LG*n*)。(参见[清单 7-4](07.html#list4) 。)

**链表。**代表序列的数组的另一种选择。尽管一旦找到正确的条目，修改链表是很便宜的(常数时间),但是找到这些条目通常需要线性时间。链表的实现有点像路径，每个节点指向下一个节点。注意 Python 的`list`类型实现为数组，而不是链表。(参见[第二章](02.html)。)

**合并排序。**原型分治算法。它把要排序的序列分成两半，递归排序两半，然后线性时间合并排序后的两半。总运行时间为θ(*n*LG*n*)。(参见[清单 6-5](06.html#list5) 。)

**矿氏算法。**一种算法，通过标记通道入口和出口来亲自穿越实际的迷宫。在许多方面类似于迭代深化 DFS 或 BFS。(参见[第五章](05.html)。)

**普里姆的算法。**通过重复添加最靠近树的节点来增长最小生成树。它本质上是一种遍历算法，使用优先级队列，就像 Dijkstra 的算法一样。(参见[清单 7-5](07.html#list5) 。)

**基数排序。**按数字(元素)对数字(或其他序列)进行排序，从最低有效位开始。只要数字的数量是恒定的，并且可以在线性时间内对数字进行排序(例如，使用计数排序)，总运行时间就是线性的。重要的是，对数字使用的排序算法是*稳定的*。(参见[第 4 章](04.html)。)

**随机选择。**找到中值，或者一般来说，第 *k* 阶统计量(第 *k* 阶最小元素)。有点像“半快速排序”它随机(或任意)选择一个 *pivot* 元素，并将其他元素划分到 pivot 的左边(较小的元素)或右边(较大的元素)。然后搜索继续在右边部分进行，有点像二分搜索法。不能保证完全平分，但是期望的运行时间仍然是线性的。(参见[清单 6-3](06.html#list3) 。)

**选择。**相当不现实，但保证线性，随机选择的同胞。它的工作方式如下:将序列分成五个一组。使用插入排序找到每个中值。使用 select 递归查找这些中间值的中间值。用这个中线作为支点，分割元素。现在在正确的一半上运行 select。换句话说，它类似于随机选择——不同之处在于，它可以保证某个百分比最终会位于中枢的任一侧，从而避免完全不平衡的情况。实际上，这不是一个你可能会在实践中用到的算法，但是了解它是很重要的。(参见[第六章](06.html)。)

**选择排序。**一个简单的二次运行时间排序算法。非常类似于插入排序，但不是重复地将下一个元素插入排序的部分，而是重复地在未排序的区域中查找(即选择)最大的元素(并与最后一个未排序的元素交换)。(参见[清单 4-4](04.html#list4) 。)

**蒂姆索特。**一种基于归并排序的超副本原地排序算法。在没有任何处理特殊情况的显式条件的情况下，它能够考虑部分排序的序列，包括反向排序的片段，因此可以比看起来可能的速度更快地对许多真实世界的序列进行排序。在`list.sort`和`sorted`中的实现也真的很快，所以如果你需要排序，那就是你应该使用的。(参见第 6 章中[timsort 上的“黑盒”侧栏。)](06.html)

**通过引用计数进行拓扑排序。**排序一个 DAG 的节点，使所有的边从左到右。这是通过计算每个节点的入边数来实现的。入度为零的节点保持在队列中(可能只是一个集合；顺序无所谓)。从队列中取出节点，并按拓扑排序顺序放置。当您这样做时，您会减少该节点有边的节点的计数。如果它们中的任何一个达到零，它们就被放入队列中。(参见[第四章](04.html)。)

**用 DFS 进行拓扑排序。**对 DAG 节点进行拓扑排序的另一个算法。这个想法很简单:执行一个 DFS 并按照逆完成时间对节点进行排序。要轻松获得线性运行时间，您可以简单地将节点添加到您的订单中，因为它们在 DFS 中接收它们的完成时间。(参见[清单 5-7](05.html#list7) 。)

**特雷莫算法。**和 Ore 的算法一样，这种算法被设计成在走迷宫时由人来执行。一个执行 Tremaux 算法的人所追踪到的模式，本质上和 DFS 是一样的。(参见[第五章](05.html)。)

**绕树两圈。**度量 TSP 问题的近似算法，保证产生的解的成本至多是最优解的两倍。首先，它构建一个最小生成树(小于最优值)，然后它“绕过”该树，走捷径以避免两次访问同一条边。由于公制，这保证比走每边两次更便宜。这最后一次遍历可以通过前序 DFS 来实现。(参见[清单 11-1](11.html#list1) 。)

__________________

[<sup>1</sup>](#_Fn1) 戏谑地归于 Lt. Cdr。《星际迷航:下一代》的乔治·拉·福吉。

[<sup>2</sup>](#_Fn2) 注意，在一般(可能是非二元)图中寻找匹配不在本书的讨论范围之内。