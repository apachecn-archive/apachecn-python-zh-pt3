# 9.组织测试数据

质量工程师走进一家酒吧。在第一杯啤酒上桌之前，迅速点了第二杯啤酒。—@botticus

我们在前一章中的测试很容易编写。每个测试只需要很少的输入，所以测试函数最多只有三四行。但是如果我们想为更复杂的情况编写测试呢？我们需要仔细查看与我们的测试相关的数据。理想情况下，我们希望测试不同的数据，以覆盖尽可能多的边界情况(见图 [9-1](#Fig1) )。同时，我们不能通过测试来覆盖程序的每一个可能的输入。如何实现数据驱动测试？在这一章中，我们将遇到有效地组织我们的测试和相应数据的最佳实践。我们将实现需要准备好的示例数据的测试，并从数据和测试中创建一系列测试，以隔离程序内的模块间依赖。我们将从测试在 MazeRun 移动板条箱的几个特定场景开始，我们还没有检查:

*   把板条箱移到角落。
*   来回移动板条箱。
*   移动到不同路径上的相同位置。
*   搬几个板条箱。

![A419627_1_En_9_Fig1_HTML.jpg](A419627_1_En_9_Fig1_HTML.jpg)

图 9-1。

Test data is like collecting diverse objects and checking which of them burn

这种测试场景更加复杂，可能会发生在真实的游戏场景中。因此，它们给了我们一个机会去发现意想不到的错误，这些错误会通过简单的测试而不被注意到。我们的场景有一个共同点，它们由多个步骤组成，需要一些准备工作。

## 使用夹具

当针对多种情况编写测试时，测试数据通常会在几个测试中重复。在第 [8](08.html) 章中，我们编写了一个助手函数来准备迷宫并执行断言 s。这里，我们将使用 py.test 提供的快捷方式，它允许我们更灵活地重用我们的测试数据:fixtures。py.test 中的 fixture 是一个为一个或多个测试返回数据的函数。要创建一个 fixture，我们需要将`@` `pytest.fixture`装饰器应用到函数中。测试前会自动调用 fixture。假设我们想要实现我们的第一个测试场景:将一个板条箱移动到一个角落。我们从导入几个模块开始，使用与上一章相同的级别(见图 [9-2](#Fig2) )。然后我们实现 fixture 函数:

![A419627_1_En_9_Fig2_HTML.jpg](A419627_1_En_9_Fig2_HTML.jpg)

图 9-2。

The level used for several scenario is provided by the level fixture

```py
from .draw_maze import parse_grid
from .moves import move
from .moves import LEFT, RIGHT, UP, DOWN
import pytest

LEVEL = """#######
#.....#
#..o..#
#.o*o.#
#..o..#
#.....#
#######"""

@pytest.fixture
def level():
    """A level with four single crates"""
    return parse_grid(LEVEL)

```

夹具`level`由一条线组成。这不是一件坏事。创建我们的测试数据的过程可能会在以后变得容易(例如，如果我们决定以后使用类)。现在，我们可以通过简单地添加`level`作为附加参数，在测试函数中使用我们的 fixture。要将顶部的板条箱移到角落，我们需要将它向上推，绕过它，然后向左推三次:

```py
def test_move_crate_to_corner(level):
    """Moves top crate to upper left corner"""
    for d in [UP, RIGHT, UP, LEFT, LEFT, LEFT]:
        move(level, d)
    assert level[1][1] == 'o'

```

当我们用上一章更新的 move 函数调用`py.test`时，测试通过。注意，我们不必关心告诉我们的测试函数`level`参数来自哪里。py.test 为我们做了这些！

Reminder

如果运行测试不起作用，在调用`py.test.`之前尝试`export` `PYTHONPATH` `=.`

只有当我们不止一次使用时，创建夹具才变得有用。对于我们的第二个场景，我们将来回移动一个板条箱。这是一个简单的健全性检查。好的测试通常包括一个循环或重复的操作，例如读一个文件，写一个文件，然后再读一次，以确保数据在过程中不会改变。来回移动板条箱也是为了同样的目的。即使移动一次板条箱工作正常，第二次也可能会卡住。这次我们将在测试中使用一个`assert`来比较两个列表

```py
def test_move_crate_back_forth(level):
    """Sanity check: move the top crate twice"""

    for d in [LEFT, UP, RIGHT, UP, RIGHT, RIGHT, DOWN, LEFT, LEFT, LEFT]:
        move(level, d)
    assert level[2] == list('#o*   #')

```

两项测试都通过了。这里我们可能会注意到一个关于夹具的重要事实:两个测试都移动顶部的板条箱。更重要的是，我们的第一次测试把板条箱推到了一个它应该永远呆在那里的角落。尽管如此，我们的第二次测试通过了。这是可能的，因为每次测试前都会重新创建夹具。py.test 负责在每次测试前通过再次调用`level`将板条箱重置到其起始位置。

### 范围参数

有时创建夹具会花费很多时间(例如，读取一个巨大的文件、创建一个数据库、启动 web 服务等。).如果许多测试使用如此昂贵的夹具，测试执行将会变慢。如果数据没有改变，我们可以通过设置`scope`参数来指示 py.test 只为整个测试模块初始化一次夹具。我们将`fixture`装饰器替换为

```py
@pytest.fixture(scope='module')

```

请注意，在我们的示例中，第二次执行的测试将会失败，因为夹具中的顶部板条箱已经在其他地方了。相互干扰的测试很难调试，这就是为什么我们将 scope 参数保留为默认值(函数级别)。

## 测试参数化

另一个典型的情况是，我们想要编写许多类似的测试。假设我们想要检查另一个测试场景:移动到不同路径上的相同位置。假设我们有以下路径通向`level`夹具中的位置(`2, 2`):

```py
PATHS = [
    (UP, LEFT),
    (LEFT, UP),
    (RIGHT, UP, LEFT, LEFT),
    (DOWN, DOWN),  # wrong on purpose
]

```

为了避免代码重复，我们可以使用`for`循环来测试这些路径:

```py
def test_paths():
    for path in PATHS:
        level = parse_grid(LEVEL)
        for direction in path:
            move(level, direction)
        assert level[2][2] == '*'

```

然而，这种方法有严重的缺点:

*   我们不能使用我们的 fixture `level`，因为我们需要在测试中多次重新初始化它。
*   只要一条路径失败，整个测试就会失败。我们不知道有多少条路径出现故障。
*   如果一条路径失败，其余的路径将不会被执行。我们不会知道他们是否会失败。

一个更好的选择是从我们的数据中自动生成测试。在 py.test 中，这种策略被称为测试参数化。我们编写一个测试函数，并指示 py.test 用不同的参数调用这个测试函数。每个调用将导致一个单一的测试。为了使用测试参数化，我们应用了`@` `pytest.mark.parametrize`装饰器:

```py
@pytest.mark.parametrize('path', PATHS)
def test_paths(path, level):
    """Different paths lead to the same spot"""
    for direction in path:
        move(level, direction)
    assert level[2][2] == '*'

```

当我们运行测试时，我们会看到四个新的测试。`PATHS`中的每个条目产生一个单独的测试函数。py.test 给每个测试分配编号，这样我们就可以更容易地识别它们。事实上，第四个测试失败了，因为(`DOWN, DOWN`)不是左上角的有效路径。在输出中，我们看到`test_paths[path3]`正在失败(索引照常从 0 开始):

```py
test_data.py .....F

================================ FAILURES =================================
_____________________________test_paths[path3]_____________________________

path = ((0, 1), (0, 1))
level = [['#', '#', '#', '#', '#', '#', ...], ['#', '.', '.', '.', '.', '.',
...], ['#', '.', '.', 'o', '.', '.', ...], ['#', '.', 'o', ' ', 'o', '.',
...], ['#', '.', '.', '*', '.', '.', ...], ['#', '.', '.', 'o', '.', '.',
...], ...]

    @pytest.mark.parametrize('path', PATHS)
    def test_paths(path, level):
        """Different paths lead to the same spot"""

        for direction in path:
            move(level, direction)
>       assert level[2][2] ==  '*'
E       assert '.' == '*'
E         - .
E         +  *

test_data.py:50:  AssertionError
=================== 1 failed, 5 passed in 0.09 seconds ====================

```

如果我们预期一个测试会失败，我们可以在定义`PATHS:`时使用`pytest.mark.xfail`函数将测试标记为“预期失败”

```py
PATHS = [
    (UP, LEFT),
    (LEFT, UP),
    (RIGHT, UP, LEFT, LEFT),
    pytest.mark.xfail((DOWN, DOWN))
]

```

py.test 将在输出中用'`x`'表示该测试。最佳实践是将`xfail`作为一个占位符来标记需要在以后修复的测试。

### 多参数

通过测试参数化，我们可以用一个装饰器为一个测试函数提供多个参数。这种模式通常用于向测试提供输入数据和相应的预期输出。这里我们只举一个简短的例子。我们的输入应该是一个运动路径，我们的预期输出是玩家的最终 x/y 位置:

```py
PATH_PLAYERPOS = [
    ((LEFT,), 2, 3),
    ((LEFT, RIGHT), 3, 3),
    ((RIGHT, RIGHT), 4, 3),
]

@pytest.mark.parametrize('path, expected_x, expected_y', PATH_PLAYERPOS)
def test_move_player(level, path, expected_x, expected_y):
    """Player position changes correctly"""

    for direction in path:
        move(level, direction)
    assert level[expected_y][expected_x] == '*'

```

在`'@pytest.mark.parametrize'`装饰器中，参数名以字符串的形式给出。py.test 自动将它们分配给我们的测试函数的参数，这给了我们三个额外的通过测试。

### 参数化夹具

测试参数化是使测试代码更短更简单的好策略。参数化夹具是将`@pytest.mark.parametrize`装饰器应用于测试的一种替代方法。例如，我们可以检查关卡中的点是否有任何不同。如果我们定义一个相同的水平，但没有点，我们会期望相同的结果。要创建级别，字符串替换就足够了:

```py
LEVEL_NO_DOTS = LEVEL.replace('.', ' ')

```

我们不想复制到目前为止编写的所有测试函数，而是想告诉 py.test 将所有东西运行两次:一次在关卡中有圆点，一次没有。创建参数化夹具类似于测试参数化。这一次，我们需要将测试数据作为`params`参数添加到`@pytest.fixture`装饰器中，并在`request.params.`中使用它。我们通过替换`level`夹具来实现这一点:

```py
@pytest.fixture(params=[LEVEL, LEVEL_NO_DOTS])
def level(request):
    """A level with four single crates"""
    return parse_grid(request.param)

```

使用`level`夹具的每个测试都在两个级别中的每一个级别上执行一次。因此，我们有效地测试了两倍多的情况！通过编写四个测试函数，我们已经涵盖了 16 种不同的情况。这应该使我们的板条箱功能充分测试。

Hint

测试夹具和测试参数化在 py.test 中配合得非常好。我们可以在单个测试函数中结合多个参数化夹具和测试参数化。这样，您可以用很少的代码轻松地生成数百个测试，因为 py.test 会在生成测试时遍历所有的参数组合。在使用参数化测试时，要注意执行时间！

## 嘲弄的

在这一节中，我们将关注一个更具挑战性的测试环境:我们如何测试连接到其他组件的程序的一部分？如果这些组件在测试中做了我们不希望发生的事情怎么办？假设我们想测试一个向打印模块发送文档的函数。这是否意味着每次运行测试时，我们都必须打开打印机，插入纸张，并观察打印的页面？更糟糕的是，如果外部组件正在等待用户输入呢？幸运的是，Python 为这种场景提供了一个优雅的解决方案:模仿。

模拟是在我们的程序中替代真实对象的假对象。Mock 模拟被替换对象的行为，但实际上不做任何事情。使用 Mock，我们可以将正在测试的组件与其依赖项隔离开来，并检查 Mock 是否被调用。由于 Python 中的动态类型系统，模仿几乎可以插入到任何地方。模块`unittest` `.mock`给了我们一个创建模拟的舒适界面。

假设我们想在 MazeRun 中测试图形。详细测试图形(捕获图像并分析其内容)会导致惊人的开销。如果我们假设 Pygame 工作正常的话，大部分甚至是不必要的。我们需要知道的是是否已经对 Pygame 函数进行了相应的调用。下面我们通过两个`unittest.mock`的例子来说明它的用法。为了简单起见，我们想要测试`draw`，一个绘制单个图块的短函数:

```py
from pygame import image, Rect
import pygame

pygame.init()
pygame.display.set_mode((80, 60))

def draw(surface):
    img = image.load('../images/tiles.xpm')
    surface.blit(img, Rect((0, 0, 32, 32)), Rect((0, 0, 32, 32)))
    pygame.display.update()

```

首先，我们将测试 draw 函数是否真的在调用`pygame.display.update`来更新屏幕。为此，我们用一个 Mock 替换了`pygame.display.update`。`@mock.patch`装潢师会处理这些:

```py
from unittest import mock

@mock.patch('pygame.display.update')
def test_mocking(mock_update):
    display = pygame.display.get_surface()
    draw(display)
    assert mock_update.called is True
    assert mock_update.call_count == 1

```

装饰器自动将创建的模拟交给我们的测试函数。我们可以给它取任何我们喜欢的名字(这里，`mock_update`)。这两个`assert`语句使用了 Mock 的两个属性，都验证了我们的 Mock 函数已经被调用。

对于第二个测试，我们想看看是否在`display`对象上画了什么。为此，我们从`MagicMock`类中创建一个模拟对象来代替`display:`

```py
def test_blit():
    mock_disp = mock.MagicMock(name='display')
    draw(mock_dist)
    assert mock_disp.blit.called is True

```

两项测试都通过了。`MagicMock`对象如何知道自己有一个`blit`方法？`MagicMock`类的一个实用属性是，它对所有事情都说“是”,并在需要时为自己创建新属性。这个属性使得模仿有点危险，因为我们可能会意外地创建通过测试。

```py
def test_bad_mocks():

  mo = mock.MagicMock()
  assert mo.twenty_blue_dolphins()
  assert mo.foo.bar('spam')['eggs']
  assert mo.was_called()  # wrong method that passes
  assert mo.caled         # typo that passes!

```

通常，模仿是替换外部组件的最佳实践:网络操作、时钟、随机数、输入/输出流等等。我们可以模仿`os.environ`在测试期间创建假的环境变量。我们可以模仿`time.sleep`来减少延迟并加速我们的测试。我们可以模仿`urllib`来创建一个总是有效的网络连接。模块`unittest.mock`提供了许多有趣的选项，值得一读。详见 [`https://docs.python.org/3/library/unittest.mock.html`](https://docs.python.org/3/library/unittest.mock.html) 。

## 测试输出文件

在许多应用程序中，我们需要测试程序产生的输出文件是否正确。涉及文件的测试通常会带来至少四个挑战:

*   我们需要先读取文件(作为字符串或使用支持库)，然后才能解释其内容。
*   通常有很多信息需要我们解析、构造、过滤等等。
*   读取文件的测试可能在许多方面失败(错误的内容、错误的路径、缺少写权限)。因此，测试结果更难解释。
*   如果我们的测试创建了一个文件，我们需要在之后清理它。否则，下一次测试可能会通过，因为文件仍然在那里，即使我们在此期间破解了代码。

在这些挑战中，最后一个是最危险的，因为它可能会掩盖我们程序中的缺陷。我们将首先处理这个问题。为了避免测试留下文件的问题，我们可以尝试用`os.remove`自己清理输出文件:

```py
import os

def test_file_output():
    open('output.txt', 'w').write("Hello  World!")  # the code being tested
    assert os.path.exists('output.txt')
    os.remove('output.txt')

```

只要代码工作正常或因异常而终止，这就很好。该测试中的潜在缺陷发生在以下事件序列中:

1.  被测试的代码创建文件，但是随后崩溃并出现异常。测试失败，但输出文件在那里。
2.  在下一次测试运行之前，我们试图修复代码，但意外的是它什么也做不了。
3.  在下一次测试运行中，代码什么也不做，但是测试仍然会找到该文件。测试通过。

更好(更安全)的替代方法是在测试前删除输出文件。但是接下来，我们会用输出文件来填充我们的磁盘。您可能已经猜到，对于这种情况，有一些很好的捷径。

### 测试后清理

py.test 提供了一种测试后清理的机制。功能`teardown_function`和`teardown_module`在测试(或模块中的所有测试)完成后执行。测试前运行的相应函数分别是`setup_function`和`setup_module`。为了在测试完成后删除输出文件，我们需要编写

```py
import os

def teardown_function(function):
    if os.path.exists('output.txt'):
        os.remove('output.txt')

def test_file_output():
    open('output.txt',  'w').write("Hello  World!")  # the code being tested
    assert os.path.exists('output.txt')

```

这种方法的主要优点是，即使测试因异常而终止，也会在每次测试后自动调用 teardown 函数。将清理代码从我们的测试中分离出来是一个最佳实践。

Hint

如果您对清理单个夹具感兴趣，请查看屈服夹具的 py.test 文档: [`http://doc.pytest.org/en/latest/fixture.html#fixture-finalization-executing-teardown-code`](http://doc.pytest.org/en/latest/fixture.html#fixture-finalization-executing-teardown-code) 。

### 使用临时文件

另一种可能是使用临时文件。Python 标准库中的`tempfile`模块允许我们创建临时文件对象，这些对象随后会自动删除:

```py
import tempfile

def test_file_output():
    with tempfile.TemporaryFile('w') as f:
        f.write("Hello World!")  # the code being tested

```

在这种情况下，我们的测试不需要 teardown 函数。`TemporaryFile`对象要求我们的代码接受文件对象作为输入。如果我们需要一个物理文件(例如文件名)，在 py.test 中使用`tmpdir` fixture 是一个更好的主意:

```py
def test_file_output_with_tempdir(tmpdir):
    tempf = tmpdir.join('output.txt')
    tempf.write("Hello  World!") # the code being tested
    content = tempf.read()
    assert content == "Hello World!"

```

`tmpdir` fixture 的一个有用的方面是测试结束后不会自动删除临时文件。在 Unix 上，它们存储在`/tmp`目录中，在那里它们不太可能干扰我们程序的其余部分。如果测试失败，将显示确切的路径。这使得`tmpdir`成为存储输出以供以后诊断的好地方。详情请查阅 py.test 文档: [`http://docs.pytest.org/en/latest/tmpdir.html`](http://docs.pytest.org/en/latest/tmpdir.html) 。

### 将输出文件与测试数据进行比较

当我们生成输出文件(计算结果、报告、日志文件)时，有许多细节需要测试。手动创建一个正确的样本文件，并将样本与实际输出进行比较，通常比解析文件和为每个细节编写测试更容易。Python 标准库提供了两个模块来帮助我们:

#### filecmp 模块

`filecmp.cmp`函数接受两个文件对象并返回`True`或`False`。假设我们有一个文件`'output.txt'`包含测试结果，另一个文件`'expected.txt'`包含手工准备的样本，我们可以用

```py
import filecmp

def test_compare_files:
    open('output.txt', 'w').write("Hello World!")  # the code being tested
    assert filecmp.cmp('output.txt', 'expected.txt')

```

这种方法的缺点是，如果文件不相等，我们将看不到它们有什么不同。为此，我们需要第二个模块。

#### difflib 模块

`difflib`模块逐行比较两个文件，并产生类似于 Unix `diff`命令的输出。函数`difflib.ndiff`接受两个字符串列表。`difflib.ndiff`函数的输出对于测试断言不是很有用，因为如果测试失败，py.test 不会显示完整的输出。但是我们可以扩展前面的测试来打印关于文件不匹配的信息:

```py
def test_compare_files():
    open('output.txt', 'w').write("***Hello World***") # the code being tested
    lines_result = open('output.txt').readlines()
    lines_expected = open('expected.txt').readlines()
    print('\n'.join(difflib.ndiff(lines_result, lines_expected)))
    assert filecmp.cmp('output.txt', 'expected.txt')

```

如果测试失败，py.test 只显示标准输出(和差异)。这就是为什么这个例子包含了一些额外的星号。我们获得了单个字符的不匹配:

```py
-------------------------- Captured  stdout  call ---------------------------
- ***Hello World***
? ---           ˆˆˆ

+  Hello  World!
?              ˆ

```

### 涉及大文件的测试的最佳实践

在测试大型数据文件时，发现差异并不是唯一的问题。此外，首先设计测试是具有挑战性的。我们应该测试什么？我们需要多少测试？对于一个大的输出文件，很明显我们不能测试所有的东西。在下面的列表中，您会发现一些涵盖多种情况的典型测试:

1.  首先测试文件是否在那里。
2.  测试文件是否不为空。
3.  读取文件并检查它是否有正确的条目数。
4.  将文件与样本文件进行匹配。
5.  检查一些典型的细节，不是全部。
6.  在将输出数据写入文件之前，对其进行测试。通常写作本身是琐碎的，或者可以委托给像`csv`或`json`这样的支持库。

## 生成随机测试数据

许多测试需要包含姓名、电子邮件地址或简单文本的样本数据记录。我们自己创造几个虚拟人很有趣，但创造一整本电话簿就不好玩了。faker 包[帮助](https://github.com/joke2k/faker)我们为许多常见和不太常见的字段生成随机数据。我们可以安装 faker

```py
pip install faker

```

这个包为我们提供了一个`Faker`对象，它的方法随机生成数据:

```py
In [1]: import faker
In [2]: f = faker.Faker()

In [3]: f.date()
Out[3]: '1979-12-17'

In [4]: f.name()
Out[4]: u'Sonji Moore'

In [5]: f.sentence()
Out[5]: u'Unde ea quidem asperiores voluptate eos adipisci sed.'

```

生成的数据涵盖了许多边界情况。例如，`f.name()`经常抛出 PhDs、royalty 和其他前缀和后缀，如果考虑得太晚，会让开发者头疼。faker 中有很多方法可以生成随机测试数据。值得看一下`dir(f)`的输出。

## 在哪里存储测试数据？

到目前为止，我们将大部分测试数据存储在带有测试函数的 Python 文件中。这是一个公认的最佳实践，即使在非常大的测试集中也能找到(例如，在 Python 标准库的测试中)。但是，有一些替代方案值得一提。在这里，我们将简要地看一下它们。

### 测试数据模块

将测试数据(例如，所有夹具)分组到单独的模块中。这种方法的优点是多个测试模块可以访问相同的数据。

### 测试数据目录

如果您的测试需要文件(输入好的/坏的/奇异的例子，样本输出),那么将它们分组在一个单独的目录中是值得的。这个集合可能会在一段时间后发展出自己的生命。如果您存储了您或您的用户发现的令人讨厌的例子，测试数据就会成为项目集体记忆中有价值的一部分。

### 测试数据库

当您的程序使用数据库时，您可能需要一个专用的测试数据库。实践中经常发现两种方法。首先，您可以在测试中创建数据库。每次开始测试时，fixture 都会创建一个新的数据库，用数据填充它，然后销毁数据库。这种方法的缺点是从头开始创建数据库通常很慢。哪怕延迟只有几秒钟，这都会拖累你的开发速度。其次，您可以维护一个专用的测试数据库。您永久地保留一个数据库用于测试。这种方法往往更快，并且它给你一个地方来存储你的测试例子。这种方法的缺点是维护数据一致性更加困难:总是存在代码意外更改数据并破坏测试数据库的风险。有一些策略可以降低风险(例如，只读访问或使用事务)，但是一般来说，您需要关注如何管理数据库。

没有完美的解决方案，维护一个非常大的测试数据集本身就是一个有趣的项目。

## 最佳实践

*   Fixtures 是为测试函数准备数据的函数。
*   参数化测试从数据条目列表中创建多个测试。
*   模仿使用用`unittest.mock`模块生成的假对象。
*   用模拟代替外部对象，测试代码的依赖性变得更简单。
*   py.test 中的清理函数在测试完成后被调用。
*   由`tmpfile`和`tmpdir` fixture 创建的临时文件是测试生成的输出文件的好地方。
*   filecmp 和 difflib 模块有助于比较文件。
*   faker 库创建随机数据用于测试。
*   有了多方面的投入，就不可能详尽无遗地涵盖所有的边界情况。一个粗略的指导方针是写尽可能多的测试和尽可能少的测试。